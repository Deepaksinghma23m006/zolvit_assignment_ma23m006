{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":186059600,"sourceType":"kernelVersion"},{"sourceId":33146,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":27739,"modelId":39106},{"sourceId":33551,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":28083,"modelId":39106}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-10-13T12:31:58.448660Z","iopub.execute_input":"2024-10-13T12:31:58.449013Z","iopub.status.idle":"2024-10-13T12:31:59.385879Z","shell.execute_reply.started":"2024-10-13T12:31:58.448951Z","shell.execute_reply":"2024-10-13T12:31:59.384848Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/inference-llama-3-8b/__results__.html\n/kaggle/input/inference-llama-3-8b/submission.csv\n/kaggle/input/inference-llama-3-8b/__notebook__.ipynb\n/kaggle/input/inference-llama-3-8b/__output__.json\n/kaggle/input/inference-llama-3-8b/custom.css\n/kaggle/input/llama-3/pytorch/8b-chat/1/consolidated.00.pth\n/kaggle/input/llama-3/pytorch/8b-chat/1/LICENSE\n/kaggle/input/llama-3/pytorch/8b-chat/1/MODEL_CARD.md\n/kaggle/input/llama-3/pytorch/8b-chat/1/params.json\n/kaggle/input/llama-3/pytorch/8b-chat/1/model.py\n/kaggle/input/llama-3/pytorch/8b-chat/1/USE_POLICY.md\n/kaggle/input/llama-3/pytorch/8b-chat/1/Llama3_Repo.jpeg\n/kaggle/input/llama-3/pytorch/8b-chat/1/example_text_completion.py\n/kaggle/input/llama-3/pytorch/8b-chat/1/test_tokenizer.py\n/kaggle/input/llama-3/pytorch/8b-chat/1/requirements.txt\n/kaggle/input/llama-3/pytorch/8b-chat/1/tokenizer.py\n/kaggle/input/llama-3/pytorch/8b-chat/1/eval_details.md\n/kaggle/input/llama-3/pytorch/8b-chat/1/generation.py\n/kaggle/input/llama-3/pytorch/8b-chat/1/__init__.py\n/kaggle/input/llama-3/pytorch/8b-chat/1/example_chat_completion.py\n/kaggle/input/llama-3/pytorch/8b-chat/1/tokenizer.model\n/kaggle/input/llama-3/pytorch/8b-chat/1/setup.py\n/kaggle/input/llama-3/transformers/8b-chat-hf/1/model.safetensors.index.json\n/kaggle/input/llama-3/transformers/8b-chat-hf/1/model-00003-of-00004.safetensors\n/kaggle/input/llama-3/transformers/8b-chat-hf/1/config.json\n/kaggle/input/llama-3/transformers/8b-chat-hf/1/LICENSE\n/kaggle/input/llama-3/transformers/8b-chat-hf/1/model-00001-of-00004.safetensors\n/kaggle/input/llama-3/transformers/8b-chat-hf/1/model.py\n/kaggle/input/llama-3/transformers/8b-chat-hf/1/USE_POLICY.md\n/kaggle/input/llama-3/transformers/8b-chat-hf/1/tokenizer.json\n/kaggle/input/llama-3/transformers/8b-chat-hf/1/tokenizer_config.json\n/kaggle/input/llama-3/transformers/8b-chat-hf/1/example_text_completion.py\n/kaggle/input/llama-3/transformers/8b-chat-hf/1/test_tokenizer.py\n/kaggle/input/llama-3/transformers/8b-chat-hf/1/requirements.txt\n/kaggle/input/llama-3/transformers/8b-chat-hf/1/tokenizer.py\n/kaggle/input/llama-3/transformers/8b-chat-hf/1/model-00004-of-00004.safetensors\n/kaggle/input/llama-3/transformers/8b-chat-hf/1/eval_details.md\n/kaggle/input/llama-3/transformers/8b-chat-hf/1/special_tokens_map.json\n/kaggle/input/llama-3/transformers/8b-chat-hf/1/generation.py\n/kaggle/input/llama-3/transformers/8b-chat-hf/1/model-00002-of-00004.safetensors\n/kaggle/input/llama-3/transformers/8b-chat-hf/1/__init__.py\n/kaggle/input/llama-3/transformers/8b-chat-hf/1/example_chat_completion.py\n/kaggle/input/llama-3/transformers/8b-chat-hf/1/setup.py\n/kaggle/input/llama-3/transformers/8b-chat-hf/1/generation_config.json\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install streamlit\n!pip install pyngrok\n!pip install pdfplumber\n!pip install pdf2image\n!pip install pytesseract\n!pip install pillow\n!pip install llama-cpp-python\n","metadata":{"execution":{"iopub.status.busy":"2024-10-13T12:32:03.743547Z","iopub.execute_input":"2024-10-13T12:32:03.744118Z","iopub.status.idle":"2024-10-13T12:35:12.832537Z","shell.execute_reply.started":"2024-10-13T12:32:03.744074Z","shell.execute_reply":"2024-10-13T12:35:12.831481Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting streamlit\n  Downloading streamlit-1.39.0-py2.py3-none-any.whl.metadata (8.5 kB)\nRequirement already satisfied: altair<6,>=4.0 in /opt/conda/lib/python3.10/site-packages (from streamlit) (5.4.1)\nRequirement already satisfied: blinker<2,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from streamlit) (1.8.2)\nRequirement already satisfied: cachetools<6,>=4.0 in /opt/conda/lib/python3.10/site-packages (from streamlit) (4.2.4)\nRequirement already satisfied: click<9,>=7.0 in /opt/conda/lib/python3.10/site-packages (from streamlit) (8.1.7)\nRequirement already satisfied: numpy<3,>=1.20 in /opt/conda/lib/python3.10/site-packages (from streamlit) (1.26.4)\nRequirement already satisfied: packaging<25,>=20 in /opt/conda/lib/python3.10/site-packages (from streamlit) (21.3)\nRequirement already satisfied: pandas<3,>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from streamlit) (2.2.2)\nRequirement already satisfied: pillow<11,>=7.1.0 in /opt/conda/lib/python3.10/site-packages (from streamlit) (10.3.0)\nRequirement already satisfied: protobuf<6,>=3.20 in /opt/conda/lib/python3.10/site-packages (from streamlit) (3.20.3)\nRequirement already satisfied: pyarrow>=7.0 in /opt/conda/lib/python3.10/site-packages (from streamlit) (16.1.0)\nRequirement already satisfied: requests<3,>=2.27 in /opt/conda/lib/python3.10/site-packages (from streamlit) (2.32.3)\nRequirement already satisfied: rich<14,>=10.14.0 in /opt/conda/lib/python3.10/site-packages (from streamlit) (13.7.1)\nRequirement already satisfied: tenacity<10,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from streamlit) (8.3.0)\nRequirement already satisfied: toml<2,>=0.10.1 in /opt/conda/lib/python3.10/site-packages (from streamlit) (0.10.2)\nRequirement already satisfied: typing-extensions<5,>=4.3.0 in /opt/conda/lib/python3.10/site-packages (from streamlit) (4.12.2)\nRequirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /opt/conda/lib/python3.10/site-packages (from streamlit) (3.1.43)\nCollecting pydeck<1,>=0.8.0b4 (from streamlit)\n  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\nRequirement already satisfied: tornado<7,>=6.0.3 in /opt/conda/lib/python3.10/site-packages (from streamlit) (6.4.1)\nRequirement already satisfied: watchdog<6,>=2.1.5 in /opt/conda/lib/python3.10/site-packages (from streamlit) (5.0.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from altair<6,>=4.0->streamlit) (3.1.4)\nRequirement already satisfied: jsonschema>=3.0 in /opt/conda/lib/python3.10/site-packages (from altair<6,>=4.0->streamlit) (4.22.0)\nRequirement already satisfied: narwhals>=1.5.2 in /opt/conda/lib/python3.10/site-packages (from altair<6,>=4.0->streamlit) (1.9.0)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.11)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging<25,>=20->streamlit) (3.1.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas<3,>=1.4.0->streamlit) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas<3,>=1.4.0->streamlit) (2024.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.27->streamlit) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.27->streamlit) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.27->streamlit) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.27->streamlit) (2024.8.30)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich<14,>=10.14.0->streamlit) (2.18.0)\nRequirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->altair<6,>=4.0->streamlit) (2.1.5)\nRequirement already satisfied: attrs>=22.2.0 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (23.2.0)\nRequirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2023.12.1)\nRequirement already satisfied: referencing>=0.28.4 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.35.1)\nRequirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.18.1)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.16.0)\nDownloading streamlit-1.39.0-py2.py3-none-any.whl (8.7 MB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m48.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m93.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: pydeck, streamlit\nSuccessfully installed pydeck-0.9.1 streamlit-1.39.0\nCollecting pyngrok\n  Downloading pyngrok-7.2.0-py3-none-any.whl.metadata (7.4 kB)\nRequirement already satisfied: PyYAML>=5.1 in /opt/conda/lib/python3.10/site-packages (from pyngrok) (6.0.2)\nDownloading pyngrok-7.2.0-py3-none-any.whl (22 kB)\nInstalling collected packages: pyngrok\nSuccessfully installed pyngrok-7.2.0\nCollecting pdfplumber\n  Downloading pdfplumber-0.11.4-py3-none-any.whl.metadata (41 kB)\n\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting pdfminer.six==20231228 (from pdfplumber)\n  Downloading pdfminer.six-20231228-py3-none-any.whl.metadata (4.2 kB)\nRequirement already satisfied: Pillow>=9.1 in /opt/conda/lib/python3.10/site-packages (from pdfplumber) (10.3.0)\nCollecting pypdfium2>=4.18.0 (from pdfplumber)\n  Downloading pypdfium2-4.30.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (48 kB)\n\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m48.5/48.5 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: charset-normalizer>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from pdfminer.six==20231228->pdfplumber) (3.3.2)\nRequirement already satisfied: cryptography>=36.0.0 in /opt/conda/lib/python3.10/site-packages (from pdfminer.six==20231228->pdfplumber) (42.0.8)\nRequirement already satisfied: cffi>=1.12 in /opt/conda/lib/python3.10/site-packages (from cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (1.16.0)\nRequirement already satisfied: pycparser in /opt/conda/lib/python3.10/site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (2.22)\nDownloading pdfplumber-0.11.4-py3-none-any.whl (59 kB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m59.2/59.2 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pdfminer.six-20231228-py3-none-any.whl (5.6 MB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m58.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading pypdfium2-4.30.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.8 MB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m78.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: pypdfium2, pdfminer.six, pdfplumber\nSuccessfully installed pdfminer.six-20231228 pdfplumber-0.11.4 pypdfium2-4.30.0\nRequirement already satisfied: pdf2image in /opt/conda/lib/python3.10/site-packages (1.17.0)\nRequirement already satisfied: pillow in /opt/conda/lib/python3.10/site-packages (from pdf2image) (10.3.0)\nRequirement already satisfied: pytesseract in /opt/conda/lib/python3.10/site-packages (0.3.13)\nRequirement already satisfied: packaging>=21.3 in /opt/conda/lib/python3.10/site-packages (from pytesseract) (21.3)\nRequirement already satisfied: Pillow>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from pytesseract) (10.3.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=21.3->pytesseract) (3.1.2)\nRequirement already satisfied: pillow in /opt/conda/lib/python3.10/site-packages (10.3.0)\nCollecting llama-cpp-python\n  Downloading llama_cpp_python-0.3.1.tar.gz (63.9 MB)\n\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m63.9/63.9 MB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: typing-extensions>=4.5.0 in /opt/conda/lib/python3.10/site-packages (from llama-cpp-python) (4.12.2)\nRequirement already satisfied: numpy>=1.20.0 in /opt/conda/lib/python3.10/site-packages (from llama-cpp-python) (1.26.4)\nCollecting diskcache>=5.6.1 (from llama-cpp-python)\n  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\nRequirement already satisfied: jinja2>=2.11.3 in /opt/conda/lib/python3.10/site-packages (from llama-cpp-python) (3.1.4)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2>=2.11.3->llama-cpp-python) (2.1.5)\nDownloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: llama-cpp-python\n  Building wheel for llama-cpp-python (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for llama-cpp-python: filename=llama_cpp_python-0.3.1-cp310-cp310-linux_x86_64.whl size=3511105 sha256=9628ea5e0ae48a251f4ae5019fd523062a88330eec266e51deb009d9626dc8ad\n  Stored in directory: /root/.cache/pip/wheels/f8/b0/a2/f47d952aec7ab061b9e2a345e23a1e1e137beb7891259e3d0c\nSuccessfully built llama-cpp-python\nInstalling collected packages: diskcache, llama-cpp-python\nSuccessfully installed diskcache-5.6.3 llama-cpp-python-0.3.1\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install pyngrok\n","metadata":{"execution":{"iopub.status.busy":"2024-10-13T12:35:12.834604Z","iopub.execute_input":"2024-10-13T12:35:12.834931Z","iopub.status.idle":"2024-10-13T12:35:24.500397Z","shell.execute_reply.started":"2024-10-13T12:35:12.834893Z","shell.execute_reply":"2024-10-13T12:35:24.499415Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Requirement already satisfied: pyngrok in /opt/conda/lib/python3.10/site-packages (7.2.0)\nRequirement already satisfied: PyYAML>=5.1 in /opt/conda/lib/python3.10/site-packages (from pyngrok) (6.0.2)\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nimport re\nimport json\nimport pandas as pd\nfrom pypdf import PdfReader\nimport streamlit as st\nfrom transformers import LlamaTokenizer, LlamaForCausalLM, GenerationConfig\n\n# Load the LLaMA model and tokenizer from the Kaggle input directory\nMODEL_PATH = '/kaggle/input/llama-3/transformers/8b-chat-hf/1'\ntokenizer = LlamaTokenizer.from_pretrained(MODEL_PATH)\nmodel = LlamaForCausalLM.from_pretrained(MODEL_PATH)\n\n# Function to extract text from a PDF file\ndef get_pdf_text(pdf_doc):\n    text = \"\"\n    pdf_reader = PdfReader(pdf_doc)\n    for page in pdf_reader.pages:\n        extracted_text = page.extract_text()\n        if extracted_text:\n            text += extracted_text + \"\\n\"\n    return text\n\n# Function to call the LLaMA model for invoice data extraction\ndef call_llama_api(pages_data):\n    prompt_template = '''Extract the following fields from the invoice data: \n    - Invoice No.\n    - Quantity\n    - Date\n    - Amount\n    - Total\n    - Email\n    - Address\n    - Taxable Value\n    - SGST Amount\n    - CGST Amount\n    - IGST Amount\n    - SGST Rate\n    - CGST Rate\n    - IGST Rate\n    - Tax Amount\n    - Tax Rate\n    - Final Amount\n    - Invoice Date\n    - Place of Supply\n    - Place of Origin\n    - GSTIN Supplier\n    - GSTIN Recipient\n\n    Provide the output in JSON format. Here is the invoice data: {pages}\n    '''\n    prompt = prompt_template.format(pages=pages_data)\n\n    inputs = tokenizer(prompt, return_tensors=\"pt\").input_ids\n    generation_config = GenerationConfig(max_length=500, temperature=0.4)\n    \n    outputs = model.generate(inputs, generation_config=generation_config)\n    output_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n    \n    return output_text\n\n# Function to process multiple PDF files and extract invoice data into a DataFrame\ndef create_docs(user_pdf_list):\n    df = pd.DataFrame({\n        'Invoice No.': pd.Series(dtype='str'),\n        'Quantity': pd.Series(dtype='str'),\n        'Date': pd.Series(dtype='str'),\n        'Amount': pd.Series(dtype='float'),\n        'Total': pd.Series(dtype='str'),\n        'Email': pd.Series(dtype='str'),\n        'Address': pd.Series(dtype='str'),\n        'Taxable Value': pd.Series(dtype='float'),\n        'SGST Amount': pd.Series(dtype='float'),\n        'CGST Amount': pd.Series(dtype='float'),\n        'IGST Amount': pd.Series(dtype='float'),\n        'SGST Rate': pd.Series(dtype='float'),\n        'CGST Rate': pd.Series(dtype='float'),\n        'IGST Rate': pd.Series(dtype='float'),\n        'Tax Amount': pd.Series(dtype='float'),\n        'Tax Rate': pd.Series(dtype='float'),\n        'Final Amount': pd.Series(dtype='float'),\n        'Invoice Date': pd.Series(dtype='str'),\n        'Place of Supply': pd.Series(dtype='str'),\n        'Place of Origin': pd.Series(dtype='str'),\n        'GSTIN Supplier': pd.Series(dtype='str'),\n        'GSTIN Recipient': pd.Series(dtype='str'),\n    })\n    \n    for file in user_pdf_list:\n        st.write(f\"Processing {file.name}...\")\n        try:\n            raw_data = get_pdf_text(file)\n            if not raw_data.strip():\n                st.warning(f\"No text extracted from {file.name}. Skipping.\")\n                continue\n            \n            llama_response = call_llama_api(raw_data)\n            if not llama_response:\n                st.error(f\"Failed to extract data from {file.name}.\")\n                continue\n\n            # Parse the response and find the dictionary structure using regex\n            pattern = r'\\{(.+)\\}'\n            match = re.search(pattern, llama_response, re.DOTALL)\n            if match:\n                extracted_text = match.group(1)\n                try:\n                    # Safely evaluate the extracted text to a dictionary\n                    data_dict = json.loads(f\"{{{extracted_text}}}\")\n                    st.write(f\"Extracted Data from {file.name}: {data_dict}\")\n                except Exception as e:\n                    st.error(f\"Error parsing extracted data from {file.name}: {e}\")\n                    continue\n            else:\n                st.error(f\"No valid JSON found in the response for {file.name}.\")\n                continue\n\n            # Add the extracted data to the DataFrame\n            df = pd.concat([df, pd.DataFrame([data_dict])], ignore_index=True)\n            st.write(\"*******DONE******\")\n        except Exception as e:\n            st.error(f\"An error occurred while processing {file.name}: {e}\")\n\n    # Save the DataFrame to an Excel file\n    output_excel_file = \"extracted_invoice_data.xlsx\"\n    df.to_excel(output_excel_file, index=False)\n    st.download_button(\n        \"Download Extracted Data as Excel\",\n        output_excel_file,\n        \"application/vnd.openxmlformats-officedocument.spreadsheetml.sheet\"\n    )\n    \n    return df\n\n\n# Streamlit app function\ndef main():\n    st.set_page_config(page_title=\"Invoice Extraction Bot\")\n    st.title(\"Invoice Extraction Bot...üíÅ\")\n    st.subheader(\"I can help you in extracting invoice data\")\n    \n    # Upload the invoices (PDF files)\n    pdf_files = st.file_uploader(\n        \"Upload invoices here, only PDF files allowed\",\n        type=[\"pdf\"],\n        accept_multiple_files=True\n    )\n    \n    if st.button(\"Extract Data\"):\n        if pdf_files:\n            with st.spinner('Processing...'):\n                df = create_docs(pdf_files)\n                \n                if not df.empty:\n                    st.write(\"### Extracted Data:\")\n                    st.dataframe(df)\n                    \n                    # Allow downloading the extracted data as a CSV file\n                    data_as_csv = df.to_csv(index=False).encode('utf-8')\n                    st.download_button(\n                        \"Download data as CSV\", \n                        data_as_csv, \n                        \"invoice_data.csv\", \n                        \"text/csv\", \n                        key=\"download-invoice-csv\"\n                    )\n                    st.success(\"Extraction complete! ‚úÖ\")\n                else:\n                    st.warning(\"No data extracted from the uploaded PDFs.\")\n        else:\n            st.error(\"Please upload at least one PDF file.\")\n\n# Run the app\nif __name__ == \"__main__\":\n    main()\n","metadata":{"execution":{"iopub.status.busy":"2024-10-13T12:35:49.785955Z","iopub.execute_input":"2024-10-13T12:35:49.786369Z","iopub.status.idle":"2024-10-13T12:35:57.180239Z","shell.execute_reply.started":"2024-10-13T12:35:49.786325Z","shell.execute_reply":"2024-10-13T12:35:57.178870Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \nThe tokenizer class you load from this checkpoint is 'PreTrainedTokenizerFast'. \nThe class this function is called from is 'LlamaTokenizer'.\nYou are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama.LlamaTokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565 - if you loaded a llama tokenizer from a GGUF file you can ignore this message\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[4], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Load the LLaMA model and tokenizer from the Kaggle input directory\u001b[39;00m\n\u001b[1;32m     10\u001b[0m MODEL_PATH \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/kaggle/input/llama-3/transformers/8b-chat-hf/1\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 11\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mLlamaTokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mMODEL_PATH\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m model \u001b[38;5;241m=\u001b[39m LlamaForCausalLM\u001b[38;5;241m.\u001b[39mfrom_pretrained(MODEL_PATH)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Function to extract text from a PDF file\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2216\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, cache_dir, force_download, local_files_only, token, revision, trust_remote_code, *init_inputs, **kwargs)\u001b[0m\n\u001b[1;32m   2213\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2214\u001b[0m         logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloading file \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m from cache at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresolved_vocab_files[file_id]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 2216\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_from_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2217\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresolved_vocab_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2218\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2219\u001b[0m \u001b[43m    \u001b[49m\u001b[43minit_configuration\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2220\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minit_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2221\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2222\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2223\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2224\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_commit_hash\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2225\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_is_local\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_local\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2226\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2227\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2228\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2450\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase._from_pretrained\u001b[0;34m(cls, resolved_vocab_files, pretrained_model_name_or_path, init_configuration, token, cache_dir, local_files_only, _commit_hash, _is_local, trust_remote_code, *init_inputs, **kwargs)\u001b[0m\n\u001b[1;32m   2448\u001b[0m \u001b[38;5;66;03m# Instantiate the tokenizer.\u001b[39;00m\n\u001b[1;32m   2449\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2450\u001b[0m     tokenizer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minit_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2451\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m import_protobuf_decode_error():\n\u001b[1;32m   2452\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\n\u001b[1;32m   2453\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to load tokenizer model from SPM, loading from TikToken will be attempted instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2454\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(Google protobuf error: Tried to load SPM model with non-SPM vocab file).\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   2455\u001b[0m     )\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/llama/tokenization_llama.py:171\u001b[0m, in \u001b[0;36mLlamaTokenizer.__init__\u001b[0;34m(self, vocab_file, unk_token, bos_token, eos_token, pad_token, sp_model_kwargs, add_bos_token, add_eos_token, clean_up_tokenization_spaces, use_default_system_prompt, spaces_between_special_tokens, legacy, add_prefix_space, **kwargs)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_eos_token \u001b[38;5;241m=\u001b[39m add_eos_token\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_default_system_prompt \u001b[38;5;241m=\u001b[39m use_default_system_prompt\n\u001b[0;32m--> 171\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msp_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_spm_processor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrom_slow\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_prefix_space \u001b[38;5;241m=\u001b[39m add_prefix_space\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    175\u001b[0m     bos_token\u001b[38;5;241m=\u001b[39mbos_token,\n\u001b[1;32m    176\u001b[0m     eos_token\u001b[38;5;241m=\u001b[39meos_token,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    188\u001b[0m )\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/llama/tokenization_llama.py:198\u001b[0m, in \u001b[0;36mLlamaTokenizer.get_spm_processor\u001b[0;34m(self, from_slow)\u001b[0m\n\u001b[1;32m    196\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m spm\u001b[38;5;241m.\u001b[39mSentencePieceProcessor(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msp_model_kwargs)\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlegacy \u001b[38;5;129;01mor\u001b[39;00m from_slow:  \u001b[38;5;66;03m# no dependency on protobuf\u001b[39;00m\n\u001b[0;32m--> 198\u001b[0m     \u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLoad\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvocab_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    199\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tokenizer\n\u001b[1;32m    201\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvocab_file, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sentencepiece/__init__.py:961\u001b[0m, in \u001b[0;36mSentencePieceProcessor.Load\u001b[0;34m(self, model_file, model_proto)\u001b[0m\n\u001b[1;32m    959\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model_proto:\n\u001b[1;32m    960\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mLoadFromSerializedProto(model_proto)\n\u001b[0;32m--> 961\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLoadFromFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_file\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sentencepiece/__init__.py:316\u001b[0m, in \u001b[0;36mSentencePieceProcessor.LoadFromFile\u001b[0;34m(self, arg)\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mLoadFromFile\u001b[39m(\u001b[38;5;28mself\u001b[39m, arg):\n\u001b[0;32m--> 316\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_sentencepiece\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSentencePieceProcessor_LoadFromFile\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mTypeError\u001b[0m: not a string"],"ename":"TypeError","evalue":"not a string","output_type":"error"}]},{"cell_type":"code","source":"from transformers import PreTrainedTokenizerFast, LlamaForCausalLM, GenerationConfig\n\n# Load the model and tokenizer from the Kaggle path\nMODEL_PATH = '/kaggle/input/llama-3/transformers/8b-chat-hf/1'\n\n# Using PreTrainedTokenizerFast for better compatibility with SentencePiece models\ntokenizer = PreTrainedTokenizerFast.from_pretrained(MODEL_PATH)\nmodel = LlamaForCausalLM.from_pretrained(MODEL_PATH)\n\n# Function to extract invoice data\ndef call_llama_api(pages_data):\n    prompt_template = '''Extract the following fields from the invoice data...'''\n    prompt = prompt_template.format(pages=pages_data)\n\n    inputs = tokenizer(prompt, return_tensors=\"pt\").input_ids\n    generation_config = GenerationConfig(max_length=500, temperature=0.4)\n    \n    outputs = model.generate(inputs, generation_config=generation_config)\n    output_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n    \n    return output_text\n","metadata":{"execution":{"iopub.status.busy":"2024-10-13T12:38:11.652120Z","iopub.execute_input":"2024-10-13T12:38:11.653017Z"},"trusted":true},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"04bb61e24263408da7c7058148a82838"}},"metadata":{}}]},{"cell_type":"code","source":"pip install transformers pdfplumber\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from pyngrok import ngrok\n\n# Replace this with your actual ngrok auth token\nngrok.set_auth_token(\"2nKLK5h8I2R07l44WNljQ8judbX_7Ze6AXjJCxRaCQvXSYPFg\")\n\n","metadata":{"execution":{"iopub.status.busy":"2024-10-12T12:44:38.083268Z","iopub.execute_input":"2024-10-12T12:44:38.083601Z","iopub.status.idle":"2024-10-12T12:44:38.795861Z","shell.execute_reply.started":"2024-10-12T12:44:38.083566Z","shell.execute_reply":"2024-10-12T12:44:38.795031Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"                                                                                                    \r","output_type":"stream"}]},{"cell_type":"code","source":"from pyngrok import ngrok\n\n# Open a tunnel on the desired port\npublic_url = ngrok.connect(8501, \"http\")  # Use the port number directly without quotes and specify protocol\nprint(f\"Streamlit app is live at: {public_url}\")","metadata":{"execution":{"iopub.status.busy":"2024-10-12T07:09:26.530637Z","iopub.execute_input":"2024-10-12T07:09:26.531617Z","iopub.status.idle":"2024-10-12T07:09:26.918741Z","shell.execute_reply.started":"2024-10-12T07:09:26.531560Z","shell.execute_reply":"2024-10-12T07:09:26.917302Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Streamlit app is live at: NgrokTunnel: \"https://019f-34-90-36-47.ngrok-free.app\" -> \"http://localhost:8501\"\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install llama-cpp-python\n","metadata":{"execution":{"iopub.status.busy":"2024-10-12T07:17:31.063864Z","iopub.execute_input":"2024-10-12T07:17:31.064347Z","iopub.status.idle":"2024-10-12T07:17:44.632838Z","shell.execute_reply.started":"2024-10-12T07:17:31.064270Z","shell.execute_reply":"2024-10-12T07:17:44.631294Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Requirement already satisfied: llama-cpp-python in /opt/conda/lib/python3.10/site-packages (0.3.1)\nRequirement already satisfied: typing-extensions>=4.5.0 in /opt/conda/lib/python3.10/site-packages (from llama-cpp-python) (4.12.2)\nRequirement already satisfied: numpy>=1.20.0 in /opt/conda/lib/python3.10/site-packages (from llama-cpp-python) (1.26.4)\nRequirement already satisfied: diskcache>=5.6.1 in /opt/conda/lib/python3.10/site-packages (from llama-cpp-python) (5.6.3)\nRequirement already satisfied: jinja2>=2.11.3 in /opt/conda/lib/python3.10/site-packages (from llama-cpp-python) (3.1.4)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2>=2.11.3->llama-cpp-python) (2.1.5)\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nimport streamlit as st\nimport pdfplumber\nfrom pdf2image import convert_from_path\nimport pytesseract\nfrom PIL import Image\nimport tempfile\nimport re\nimport json\nfrom llama_cpp import Llama\n\n# Set page configuration\nst.set_page_config(page_title=\"Invoice Data Extraction\", layout=\"wide\")\n\n# Initialize LLaMA model\n@st.cache_resource\ndef load_llama_model():\n    model_path = \"/kaggle/input/llama-3/transformers/8b-chat-hf/1\"\n    \n    # Check if model path exists\n    if not os.path.exists(model_path):\n        st.error(\"Model path does not exist or is not accessible.\")\n        return None\n    \n    try:\n        # Adjust batch size and context to prevent memory issues\n        llm = Llama(\n            model_path=model_path,\n            n_ctx=1024,  # Reduce context size\n            n_batch=128,  # Reduce batch size\n            use_mlock=False  # Disable memory locking\n        )\n        return llm\n    except Exception as e:\n        st.error(f\"Error loading LLaMA model: {e}\")\n        return None\n\n\nllm = load_llama_model()\n\n# Helper functions\ndef extract_text_from_pdf(file):\n    text = \"\"\n    try:\n        with pdfplumber.open(file) as pdf:\n            for page in pdf.pages:\n                extracted = page.extract_text()\n                if extracted:\n                    text += extracted + \"\\n\"\n    except Exception as e:\n        st.error(f\"Error reading PDF: {e}\")\n        return \"\"\n    return text\n\ndef extract_text_via_ocr(file):\n    text = \"\"\n    with tempfile.TemporaryDirectory() as path:\n        try:\n            images = convert_from_path(file, output_folder=path)\n        except Exception as e:\n            st.error(f\"Error converting PDF to images: {e}\")\n            return \"\"\n        for img in images:\n            try:\n                text += pytesseract.image_to_string(img) + \"\\n\"\n            except Exception as e:\n                st.error(f\"Error with OCR on image: {e}\")\n                return \"\"\n    return text\n\ndef preprocess_text(text):\n    # Remove multiple spaces and newlines\n    text = re.sub(r'\\s+', ' ', text)\n    return text\n\ndef extract_invoice_data(text):\n    prompt = f\"\"\"\nYou are a model designed to extract invoice information. Please strictly extract and return the invoice information in the following JSON format, and nothing else:\n\nJSON Format:\n{{\n    \"Invoice Number\": \"\",\n    \"Invoice Date\": \"\",\n    \"Due Date\": \"\",\n    \"Total Amount\": \"\",\n    \"Vendor Name\": \"\",\n    \"Vendor Address\": \"\",\n    \"Buyer Name\": \"\",\n    \"Buyer Address\": \"\",\n    \"GSTIN Number\": \"\",\n    \"Bank Details\": {{\n        \"Name\": \"\",\n        \"Account Number\": \"\",\n        \"IFSC Code\": \"\"\n    }},\n    \"Payment Terms\": \"\"\n}}\n\nExtract the information strictly from the invoice text provided below:\n\n\\\"\\\"\\\\\"\"{text}\\\"\\\"\\\\\"\\\"\n\nEnsure that the JSON is valid and strictly adheres to the format. Return no additional explanations.\n\"\"\"\n    if llm:\n        try:\n            response = llm(\n                prompt,\n                max_tokens=1024,\n                temperature=0.0,\n                stop=[\"\\\"\\\"\\\"\"]\n            )\n            return response\n        except Exception as e:\n            st.error(f\"Error during LLaMA model inference: {e}\")\n            return None\n    else:\n        st.error(\"LLaMA model is not loaded.\")\n        return None\n\ndef parse_json(text):\n    try:\n        # Use regex to find the first JSON-like structure\n        json_text_match = re.search(r'\\{.*\\}', text, re.DOTALL)\n        if json_text_match:\n            json_text = json_text_match.group()\n            # Try loading the JSON\n            data = json.loads(json_text)\n            return data\n        else:\n            raise ValueError(\"No valid JSON found in the text.\")\n    except json.JSONDecodeError as e:\n        st.error(f\"JSON decode error: {e}\")\n        return None\n    except Exception as e:\n        st.error(f\"Failed to parse JSON: {e}\")\n        return None\n\n# Streamlit App\nst.title(\"üìÑ Invoice Data Extraction\")\nst.write(\"Upload your invoice PDFs (Regular, Scanned, or Mixed) to extract relevant information.\")\n\nuploaded_file = st.file_uploader(\"Choose a PDF file\", type=[\"pdf\"])\n\nif uploaded_file is not None:\n    with st.spinner(\"Processing...\"):\n        # Save uploaded file to a temporary file\n        with tempfile.NamedTemporaryFile(delete=False, suffix=\".pdf\") as tmp_file:\n            tmp_file.write(uploaded_file.read())\n            tmp_file_path = tmp_file.name\n\n        # Attempt to extract text directly\n        text = extract_text_from_pdf(tmp_file_path)\n\n        # If no text found, perform OCR\n        if not text.strip():\n            text = extract_text_via_ocr(tmp_file_path)\n\n        text = preprocess_text(text)\n\n        if not text.strip():\n            st.error(\"Failed to extract text from the PDF.\")\n        else:\n            st.subheader(\"Extracted Text\")\n            st.text_area(\"Raw Extracted Text\", text, height=300)\n\n            # Extract structured data using LLaMA model\n            model_response = extract_invoice_data(text)\n\n            if model_response is None:\n                st.error(\"Model inference failed.\")\n            else:\n                # Debugging: Display the raw model response\n                st.subheader(\"Model Response (Debug)\")\n                st.text_area(\"Raw Model Response\", str(model_response), height=300)\n\n                # Check if response is a dictionary with choices\n                if isinstance(model_response, dict) and 'choices' in model_response:\n                    if len(model_response['choices']) > 0:\n                        extracted_text = model_response['choices'][0]['text'].strip()\n                        extracted_data = parse_json(extracted_text)\n                    else:\n                        st.error(\"No choices available in the model response.\")\n                        extracted_data = None\n                else:\n                    st.error(\"Unexpected response format from the model.\")\n                    extracted_data = None\n\n                if extracted_data:\n                    st.subheader(\"Extracted Invoice Data\")\n                    st.json(extracted_data)\n\n    # Optionally, display the PDF\n    st.subheader(\"Uploaded PDF\")\n    st.info(\"Note: For privacy reasons, the PDF is not displayed here.\")\n","metadata":{"execution":{"iopub.status.busy":"2024-10-12T07:21:27.827344Z","iopub.execute_input":"2024-10-12T07:21:27.827820Z","iopub.status.idle":"2024-10-12T07:21:27.877428Z","shell.execute_reply.started":"2024-10-12T07:21:27.827773Z","shell.execute_reply":"2024-10-12T07:21:27.875191Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stderr","text":"2024-10-12 07:21:27.849 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n2024-10-12 07:21:27.852 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n2024-10-12 07:21:27.854 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n2024-10-12 07:21:27.855 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n2024-10-12 07:21:27.856 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n2024-10-12 07:21:27.857 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n2024-10-12 07:21:27.859 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n2024-10-12 07:21:27.860 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n2024-10-12 07:21:27.861 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n2024-10-12 07:21:27.862 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n2024-10-12 07:21:27.863 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n2024-10-12 07:21:27.865 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n2024-10-12 07:21:27.866 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n2024-10-12 07:21:27.867 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n2024-10-12 07:21:27.868 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n2024-10-12 07:21:27.869 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n2024-10-12 07:21:27.870 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n","output_type":"stream"}]},{"cell_type":"code","source":"# Install necessary packages\n!pip install pdfplumber pdf2image pytesseract llama-cpp-python pillow\n\n# If not already installed, install ipywidgets for interactive widgets\n!pip install ipywidgets\n\n# Import Libraries\nimport os\nimport pdfplumber\nfrom pdf2image import convert_from_path\nimport pytesseract\nfrom PIL import Image\nimport tempfile\nimport re\nimport json\nfrom llama_cpp import Llama\nimport ipywidgets as widgets\nfrom IPython.display import display, clear_output\n","metadata":{"execution":{"iopub.status.busy":"2024-10-12T08:10:21.760085Z","iopub.execute_input":"2024-10-12T08:10:21.760590Z","iopub.status.idle":"2024-10-12T08:10:49.649112Z","shell.execute_reply.started":"2024-10-12T08:10:21.760540Z","shell.execute_reply":"2024-10-12T08:10:49.647391Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"Requirement already satisfied: pdfplumber in /opt/conda/lib/python3.10/site-packages (0.11.4)\nRequirement already satisfied: pdf2image in /opt/conda/lib/python3.10/site-packages (1.17.0)\nRequirement already satisfied: pytesseract in /opt/conda/lib/python3.10/site-packages (0.3.13)\nRequirement already satisfied: llama-cpp-python in /opt/conda/lib/python3.10/site-packages (0.3.1)\nRequirement already satisfied: pillow in /opt/conda/lib/python3.10/site-packages (10.3.0)\nRequirement already satisfied: pdfminer.six==20231228 in /opt/conda/lib/python3.10/site-packages (from pdfplumber) (20231228)\nRequirement already satisfied: pypdfium2>=4.18.0 in /opt/conda/lib/python3.10/site-packages (from pdfplumber) (4.30.0)\nRequirement already satisfied: charset-normalizer>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from pdfminer.six==20231228->pdfplumber) (3.3.2)\nRequirement already satisfied: cryptography>=36.0.0 in /opt/conda/lib/python3.10/site-packages (from pdfminer.six==20231228->pdfplumber) (42.0.8)\nRequirement already satisfied: packaging>=21.3 in /opt/conda/lib/python3.10/site-packages (from pytesseract) (21.3)\nRequirement already satisfied: typing-extensions>=4.5.0 in /opt/conda/lib/python3.10/site-packages (from llama-cpp-python) (4.12.2)\nRequirement already satisfied: numpy>=1.20.0 in /opt/conda/lib/python3.10/site-packages (from llama-cpp-python) (1.26.4)\nRequirement already satisfied: diskcache>=5.6.1 in /opt/conda/lib/python3.10/site-packages (from llama-cpp-python) (5.6.3)\nRequirement already satisfied: jinja2>=2.11.3 in /opt/conda/lib/python3.10/site-packages (from llama-cpp-python) (3.1.4)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2>=2.11.3->llama-cpp-python) (2.1.5)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=21.3->pytesseract) (3.1.2)\nRequirement already satisfied: cffi>=1.12 in /opt/conda/lib/python3.10/site-packages (from cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (1.16.0)\nRequirement already satisfied: pycparser in /opt/conda/lib/python3.10/site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (2.22)\nRequirement already satisfied: ipywidgets in /opt/conda/lib/python3.10/site-packages (7.7.1)\nRequirement already satisfied: ipykernel>=4.5.1 in /opt/conda/lib/python3.10/site-packages (from ipywidgets) (6.29.4)\nRequirement already satisfied: ipython-genutils~=0.2.0 in /opt/conda/lib/python3.10/site-packages (from ipywidgets) (0.2.0)\nRequirement already satisfied: traitlets>=4.3.1 in /opt/conda/lib/python3.10/site-packages (from ipywidgets) (5.14.3)\nRequirement already satisfied: widgetsnbextension~=3.6.0 in /opt/conda/lib/python3.10/site-packages (from ipywidgets) (3.6.9)\nRequirement already satisfied: ipython>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from ipywidgets) (8.21.0)\nRequirement already satisfied: jupyterlab-widgets>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from ipywidgets) (3.0.11)\nRequirement already satisfied: comm>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets) (0.2.2)\nRequirement already satisfied: debugpy>=1.6.5 in /opt/conda/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets) (1.8.1)\nRequirement already satisfied: jupyter-client>=6.1.12 in /opt/conda/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets) (7.4.9)\nRequirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /opt/conda/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets) (5.7.2)\nRequirement already satisfied: matplotlib-inline>=0.1 in /opt/conda/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets) (0.1.7)\nRequirement already satisfied: nest-asyncio in /opt/conda/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets) (1.6.0)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets) (5.9.3)\nRequirement already satisfied: pyzmq>=24 in /opt/conda/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets) (26.0.3)\nRequirement already satisfied: tornado>=6.1 in /opt/conda/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets) (6.4.1)\nRequirement already satisfied: decorator in /opt/conda/lib/python3.10/site-packages (from ipython>=4.0.0->ipywidgets) (5.1.1)\nRequirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.10/site-packages (from ipython>=4.0.0->ipywidgets) (0.19.1)\nRequirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /opt/conda/lib/python3.10/site-packages (from ipython>=4.0.0->ipywidgets) (3.0.47)\nRequirement already satisfied: pygments>=2.4.0 in /opt/conda/lib/python3.10/site-packages (from ipython>=4.0.0->ipywidgets) (2.18.0)\nRequirement already satisfied: stack-data in /opt/conda/lib/python3.10/site-packages (from ipython>=4.0.0->ipywidgets) (0.6.2)\nRequirement already satisfied: exceptiongroup in /opt/conda/lib/python3.10/site-packages (from ipython>=4.0.0->ipywidgets) (1.2.0)\nRequirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.10/site-packages (from ipython>=4.0.0->ipywidgets) (4.9.0)\nRequirement already satisfied: notebook>=4.4.1 in /opt/conda/lib/python3.10/site-packages (from widgetsnbextension~=3.6.0->ipywidgets) (6.5.7)\nRequirement already satisfied: parso<0.9.0,>=0.8.3 in /opt/conda/lib/python3.10/site-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets) (0.8.4)\nRequirement already satisfied: entrypoints in /opt/conda/lib/python3.10/site-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (0.4)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (2.9.0.post0)\nRequirement already satisfied: platformdirs>=2.5 in /opt/conda/lib/python3.10/site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel>=4.5.1->ipywidgets) (3.11.0)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.1.4)\nRequirement already satisfied: argon2-cffi in /opt/conda/lib/python3.10/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (23.1.0)\nRequirement already satisfied: nbformat in /opt/conda/lib/python3.10/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (5.10.4)\nRequirement already satisfied: nbconvert>=5 in /opt/conda/lib/python3.10/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (6.4.5)\nRequirement already satisfied: Send2Trash>=1.8.0 in /opt/conda/lib/python3.10/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.8.3)\nRequirement already satisfied: terminado>=0.8.3 in /opt/conda/lib/python3.10/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.18.1)\nRequirement already satisfied: prometheus-client in /opt/conda/lib/python3.10/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.20.0)\nRequirement already satisfied: nbclassic>=0.4.7 in /opt/conda/lib/python3.10/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.1.0)\nRequirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.10/site-packages (from pexpect>4.3->ipython>=4.0.0->ipywidgets) (0.7.0)\nRequirement already satisfied: wcwidth in /opt/conda/lib/python3.10/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=4.0.0->ipywidgets) (0.2.13)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->ipykernel>=4.5.1->ipywidgets) (3.1.2)\nRequirement already satisfied: executing>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython>=4.0.0->ipywidgets) (2.0.1)\nRequirement already satisfied: asttokens>=2.1.0 in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython>=4.0.0->ipywidgets) (2.4.1)\nRequirement already satisfied: pure-eval in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython>=4.0.0->ipywidgets) (0.2.2)\nRequirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from asttokens>=2.1.0->stack-data->ipython>=4.0.0->ipywidgets) (1.16.0)\nRequirement already satisfied: notebook-shim>=0.2.3 in /opt/conda/lib/python3.10/site-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.2.4)\nRequirement already satisfied: mistune<2,>=0.8.1 in /opt/conda/lib/python3.10/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.8.4)\nRequirement already satisfied: jupyterlab-pygments in /opt/conda/lib/python3.10/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.3.0)\nRequirement already satisfied: bleach in /opt/conda/lib/python3.10/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (6.1.0)\nRequirement already satisfied: pandocfilters>=1.4.1 in /opt/conda/lib/python3.10/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.5.0)\nRequirement already satisfied: testpath in /opt/conda/lib/python3.10/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.6.0)\nRequirement already satisfied: defusedxml in /opt/conda/lib/python3.10/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.7.1)\nRequirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.10/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.12.3)\nRequirement already satisfied: nbclient<0.6.0,>=0.5.0 in /opt/conda/lib/python3.10/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.5.13)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.1.5)\nRequirement already satisfied: fastjsonschema>=2.15 in /opt/conda/lib/python3.10/site-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.19.1)\nRequirement already satisfied: jsonschema>=2.6 in /opt/conda/lib/python3.10/site-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.22.0)\nRequirement already satisfied: argon2-cffi-bindings in /opt/conda/lib/python3.10/site-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (21.2.0)\nRequirement already satisfied: attrs>=22.2.0 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (23.2.0)\nRequirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2023.12.1)\nRequirement already satisfied: referencing>=0.28.4 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.35.1)\nRequirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.18.1)\nRequirement already satisfied: jupyter-server<3,>=1.8 in /opt/conda/lib/python3.10/site-packages (from notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.12.5)\nRequirement already satisfied: cffi>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.16.0)\nRequirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.5)\nRequirement already satisfied: webencodings in /opt/conda/lib/python3.10/site-packages (from bleach->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.5.1)\nRequirement already satisfied: pycparser in /opt/conda/lib/python3.10/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.22)\nRequirement already satisfied: anyio>=3.1.0 in /opt/conda/lib/python3.10/site-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.4.0)\nRequirement already satisfied: jupyter-events>=0.9.0 in /opt/conda/lib/python3.10/site-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.10.0)\nRequirement already satisfied: jupyter-server-terminals in /opt/conda/lib/python3.10/site-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.5.3)\nRequirement already satisfied: overrides in /opt/conda/lib/python3.10/site-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (7.7.0)\nRequirement already satisfied: websocket-client in /opt/conda/lib/python3.10/site-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.8.0)\nRequirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.10/site-packages (from anyio>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.7)\nRequirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.10/site-packages (from anyio>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.3.1)\nRequirement already satisfied: typing-extensions>=4.1 in /opt/conda/lib/python3.10/site-packages (from anyio>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.12.2)\nRequirement already satisfied: python-json-logger>=2.0.4 in /opt/conda/lib/python3.10/site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.0.7)\nRequirement already satisfied: pyyaml>=5.3 in /opt/conda/lib/python3.10/site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (6.0.2)\nRequirement already satisfied: rfc3339-validator in /opt/conda/lib/python3.10/site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.1.4)\nRequirement already satisfied: rfc3986-validator>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.1.1)\nRequirement already satisfied: fqdn in /opt/conda/lib/python3.10/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.5.1)\nRequirement already satisfied: isoduration in /opt/conda/lib/python3.10/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (20.11.0)\nRequirement already satisfied: jsonpointer>1.13 in /opt/conda/lib/python3.10/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.4)\nRequirement already satisfied: uri-template in /opt/conda/lib/python3.10/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.3.0)\nRequirement already satisfied: webcolors>=1.11 in /opt/conda/lib/python3.10/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (24.6.0)\nRequirement already satisfied: arrow>=0.15.0 in /opt/conda/lib/python3.10/site-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.3.0)\nRequirement already satisfied: types-python-dateutil>=2.8.10 in /opt/conda/lib/python3.10/site-packages (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.9.0.20240316)\n","output_type":"stream"}]},{"cell_type":"code","source":"# Check if Tesseract is installed\n!which tesseract\n\n# If not installed, install it\n# Uncomment the following line if Tesseract is not found\n# !apt-get install -y tesseract-ocr\n","metadata":{"execution":{"iopub.status.busy":"2024-10-12T08:10:52.478536Z","iopub.execute_input":"2024-10-12T08:10:52.480166Z","iopub.status.idle":"2024-10-12T08:10:53.881626Z","shell.execute_reply.started":"2024-10-12T08:10:52.480107Z","shell.execute_reply":"2024-10-12T08:10:53.879913Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"/usr/bin/tesseract\n","output_type":"stream"}]},{"cell_type":"code","source":"# Initialize LLaMA model\ndef load_llama_model():\n    model_path = \"/kaggle/input/llama-3/transformers/8b-chat-hf/1\"  # Updated model path\n    llm = Llama(\n        model_path=model_path,\n        n_ctx=2048,\n        n_batch=512,\n        use_mlock=True  # Adjust based on your environment's capabilities\n    )\n    return llm\n\n# Load the model\nllm = load_llama_model()\n","metadata":{"execution":{"iopub.status.busy":"2024-10-12T08:14:02.561718Z","iopub.execute_input":"2024-10-12T08:14:02.562998Z","iopub.status.idle":"2024-10-12T08:14:02.699508Z","shell.execute_reply.started":"2024-10-12T08:14:02.562941Z","shell.execute_reply":"2024-10-12T08:14:02.697966Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stderr","text":"gguf_init_from_file: invalid magic characters 'ÔøΩ[\u0000\u0000'\nllama_model_load: error loading model: llama_model_loader: failed to load model from /kaggle/input/llama-3/transformers/8b-chat-hf/1\n\nllama_load_model_from_file: failed to load model\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[29], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m llm\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Load the model\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m llm \u001b[38;5;241m=\u001b[39m \u001b[43mload_llama_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[29], line 4\u001b[0m, in \u001b[0;36mload_llama_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_llama_model\u001b[39m():\n\u001b[1;32m      3\u001b[0m     model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/kaggle/input/llama-3/transformers/8b-chat-hf/1\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# Updated model path\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m     llm \u001b[38;5;241m=\u001b[39m \u001b[43mLlama\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_ctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2048\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m512\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_mlock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Adjust based on your environment's capabilities\u001b[39;49;00m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m llm\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/llama_cpp/llama.py:369\u001b[0m, in \u001b[0;36mLlama.__init__\u001b[0;34m(self, model_path, n_gpu_layers, split_mode, main_gpu, tensor_split, rpc_servers, vocab_only, use_mmap, use_mlock, kv_overrides, seed, n_ctx, n_batch, n_ubatch, n_threads, n_threads_batch, rope_scaling_type, pooling_type, rope_freq_base, rope_freq_scale, yarn_ext_factor, yarn_attn_factor, yarn_beta_fast, yarn_beta_slow, yarn_orig_ctx, logits_all, embedding, offload_kqv, flash_attn, last_n_tokens_size, lora_base, lora_scale, lora_path, numa, chat_format, chat_handler, draft_model, tokenizer, type_k, type_v, spm_infill, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    364\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(model_path):\n\u001b[1;32m    365\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel path does not exist: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    367\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stack\u001b[38;5;241m.\u001b[39menter_context(\n\u001b[1;32m    368\u001b[0m     contextlib\u001b[38;5;241m.\u001b[39mclosing(\n\u001b[0;32m--> 369\u001b[0m         \u001b[43minternals\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLlamaModel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    370\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpath_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    371\u001b[0m \u001b[43m            \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    372\u001b[0m \u001b[43m            \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    373\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    374\u001b[0m     )\n\u001b[1;32m    375\u001b[0m )\n\u001b[1;32m    377\u001b[0m \u001b[38;5;66;03m# Override tokenizer\u001b[39;00m\n\u001b[1;32m    378\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer_ \u001b[38;5;241m=\u001b[39m tokenizer \u001b[38;5;129;01mor\u001b[39;00m LlamaTokenizer(\u001b[38;5;28mself\u001b[39m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/llama_cpp/_internals.py:56\u001b[0m, in \u001b[0;36mLlamaModel.__init__\u001b[0;34m(self, path_model, params, verbose)\u001b[0m\n\u001b[1;32m     51\u001b[0m     model \u001b[38;5;241m=\u001b[39m llama_cpp\u001b[38;5;241m.\u001b[39mllama_load_model_from_file(\n\u001b[1;32m     52\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpath_model\u001b[38;5;241m.\u001b[39mencode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams\n\u001b[1;32m     53\u001b[0m     )\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 56\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to load model from file: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_model\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m model\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfree_model\u001b[39m():\n","\u001b[0;31mValueError\u001b[0m: Failed to load model from file: /kaggle/input/llama-3/transformers/8b-chat-hf/1"],"ename":"ValueError","evalue":"Failed to load model from file: /kaggle/input/llama-3/transformers/8b-chat-hf/1","output_type":"error"}]},{"cell_type":"code","source":"def extract_text_from_pdf(file_path):\n    \"\"\"\n    Extracts text from a PDF file using pdfplumber.\n    \"\"\"\n    text = \"\"\n    try:\n        with pdfplumber.open(file_path) as pdf:\n            for page in pdf.pages:\n                extracted = page.extract_text()\n                if extracted:\n                    text += extracted + \"\\n\"\n    except Exception as e:\n        print(f\"Error reading PDF: {e}\")\n        return \"\"\n    return text\n\ndef extract_text_via_ocr(file_path):\n    \"\"\"\n    Extracts text from a PDF file using OCR (pytesseract) after converting PDF pages to images.\n    \"\"\"\n    text = \"\"\n    with tempfile.TemporaryDirectory() as path:\n        try:\n            images = convert_from_path(file_path, output_folder=path)\n        except Exception as e:\n            print(f\"Error converting PDF to images: {e}\")\n            return \"\"\n        for img in images:\n            try:\n                text += pytesseract.image_to_string(img) + \"\\n\"\n            except Exception as e:\n                print(f\"Error with OCR on image: {e}\")\n                return \"\"\n    return text\n\ndef preprocess_text(text):\n    \"\"\"\n    Cleans the extracted text by removing excessive whitespace.\n    \"\"\"\n    text = re.sub(r'\\s+', ' ', text)\n    return text\n\ndef extract_invoice_data(text, llm_model):\n    \"\"\"\n    Uses the LLaMA model to extract structured invoice data from text.\n    \"\"\"\n    prompt = f\"\"\"\nYou are a model designed to extract invoice information. Please strictly extract and return the invoice information in the following JSON format, and nothing else:\n\nJSON Format:\n{{\n    \"Invoice Number\": \"\",\n    \"Invoice Date\": \"\",\n    \"Due Date\": \"\",\n    \"Total Amount\": \"\",\n    \"Vendor Name\": \"\",\n    \"Vendor Address\": \"\",\n    \"Buyer Name\": \"\",\n    \"Buyer Address\": \"\",\n    \"GSTIN Number\": \"\",\n    \"Bank Details\": {{\n        \"Name\": \"\",\n        \"Account Number\": \"\",\n        \"IFSC Code\": \"\"\n    }},\n    \"Payment Terms\": \"\"\n}}\n\nExtract the information strictly from the invoice text provided below:\n\n\\\"\\\"\\\\\"\"\" \n{text} \n\\\"\\\"\\\\\"\"\" \n\nEnsure that the JSON is valid and strictly adheres to the format. Return no additional explanations.\n\"\"\"\n    response = llm_model(\n        prompt,\n        max_tokens=1024,\n        temperature=0.0,\n        stop=[\"\\\"\\\"\\\"\"]\n    )\n    return response\n\ndef parse_json(text):\n    \"\"\"\n    Parses JSON text extracted from the model's response.\n    \"\"\"\n    try:\n        # Use regex to find the first JSON-like structure\n        json_text_match = re.search(r'\\{.*\\}', text, re.DOTALL)\n        if json_text_match:\n            json_text = json_text_match.group()\n            # Try loading the JSON\n            data = json.loads(json_text)\n            return data\n        else:\n            raise ValueError(\"No valid JSON found in the text.\")\n    except json.JSONDecodeError as e:\n        print(f\"JSON decode error: {e}\")\n        return None\n    except Exception as e:\n        print(f\"Failed to parse JSON: {e}\")\n        return None\n","metadata":{"execution":{"iopub.status.busy":"2024-10-12T08:14:20.461203Z","iopub.execute_input":"2024-10-12T08:14:20.461695Z","iopub.status.idle":"2024-10-12T08:14:20.475232Z","shell.execute_reply.started":"2024-10-12T08:14:20.461650Z","shell.execute_reply":"2024-10-12T08:14:20.473729Z"},"trusted":true},"execution_count":30,"outputs":[{"traceback":["\u001b[0;36m  Cell \u001b[0;32mIn[30], line 73\u001b[0;36m\u001b[0m\n\u001b[0;31m    \\\"\\\"\\\\\"\"\"\u001b[0m\n\u001b[0m     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected character after line continuation character\n"],"ename":"SyntaxError","evalue":"unexpected character after line continuation character (3752034076.py, line 73)","output_type":"error"}]},{"cell_type":"code","source":"import os\n\nmodel_dir = \"/kaggle/input/llama-3/transformers/8b-chat-hf/1\"\nfor root, dirs, files in os.walk(model_dir):\n    print(root)\n    for file in files:\n        print(\"  -\", file)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-12T08:16:08.690747Z","iopub.execute_input":"2024-10-12T08:16:08.691758Z","iopub.status.idle":"2024-10-12T08:16:08.699742Z","shell.execute_reply.started":"2024-10-12T08:16:08.691691Z","shell.execute_reply":"2024-10-12T08:16:08.698373Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"/kaggle/input/llama-3/transformers/8b-chat-hf/1\n  - model.safetensors.index.json\n  - model-00003-of-00004.safetensors\n  - config.json\n  - LICENSE\n  - model-00001-of-00004.safetensors\n  - model.py\n  - USE_POLICY.md\n  - tokenizer.json\n  - tokenizer_config.json\n  - example_text_completion.py\n  - test_tokenizer.py\n  - requirements.txt\n  - tokenizer.py\n  - model-00004-of-00004.safetensors\n  - eval_details.md\n  - special_tokens_map.json\n  - generation.py\n  - model-00002-of-00004.safetensors\n  - __init__.py\n  - example_chat_completion.py\n  - setup.py\n  - generation_config.json\n","output_type":"stream"}]},{"cell_type":"code","source":"# Clone the repository\n!git clone https://github.com/ggerganov/llama.cpp.git\n%cd llama.cpp\n\n# Build the conversion tool\n!make\n","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Example command (adjust based on the actual conversion tool's instructions)\n./convert-hf-to-gguf --input /kaggle/input/llama-3/transformers/8b-chat-hf/1 --output /kaggle/input/llama-3/transformers/8b-chat-hf.gguf\n","metadata":{"execution":{"iopub.status.busy":"2024-10-12T08:29:22.233868Z","iopub.execute_input":"2024-10-12T08:29:22.234332Z","iopub.status.idle":"2024-10-12T08:29:22.243564Z","shell.execute_reply.started":"2024-10-12T08:29:22.234290Z","shell.execute_reply":"2024-10-12T08:29:22.241583Z"},"trusted":true},"execution_count":36,"outputs":[{"traceback":["\u001b[0;36m  Cell \u001b[0;32mIn[36], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    ./convert-hf-to-gguf --input /kaggle/input/llama-3/transformers/8b-chat-hf/1 --output /kaggle/input/llama-3/transformers/8b-chat-hf.gguf\u001b[0m\n\u001b[0m                                                                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n"],"ename":"SyntaxError","evalue":"invalid decimal literal (1341952149.py, line 2)","output_type":"error"}]},{"cell_type":"code","source":"!pip install transformers\n!pip install accelerate\n!pip install sentencepiece\n","metadata":{"execution":{"iopub.status.busy":"2024-10-12T08:29:35.668272Z","iopub.execute_input":"2024-10-12T08:29:35.669328Z","iopub.status.idle":"2024-10-12T08:30:17.360017Z","shell.execute_reply.started":"2024-10-12T08:29:35.669266Z","shell.execute_reply":"2024-10-12T08:30:17.358081Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.45.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.15.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.25.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.5.15)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.5)\nRequirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.20.0)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.8.30)\nRequirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (0.34.2)\nRequirement already satisfied: numpy<3.0.0,>=1.17 in /opt/conda/lib/python3.10/site-packages (from accelerate) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate) (6.0.2)\nRequirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (2.4.0+cpu)\nRequirement already satisfied: huggingface-hub>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.25.1)\nRequirement already satisfied: safetensors>=0.4.3 in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.4.5)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (3.15.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (2024.6.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (2.32.3)\nRequirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (4.66.4)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->accelerate) (3.1.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.4)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2024.8.30)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\nRequirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (0.2.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForCausalLM\n\nmodel_name_or_path = \"/kaggle/input/llama-3/transformers/8b-chat-hf/1\"\n\ntokenizer = AutoTokenizer.from_pretrained(model_name_or_path)\nmodel = AutoModelForCausalLM.from_pretrained(model_name_or_path, device_map=\"auto\", torch_dtype=torch.float16)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-12T08:30:20.604151Z","iopub.execute_input":"2024-10-12T08:30:20.604710Z","iopub.status.idle":"2024-10-12T08:31:45.319138Z","shell.execute_reply.started":"2024-10-12T08:30:20.604660Z","shell.execute_reply":"2024-10-12T08:31:45.317839Z"},"trusted":true},"execution_count":38,"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"46b894b376d2453393dc0a74a1967b61"}},"metadata":{}}]},{"cell_type":"code","source":"import torch\n\ndef extract_invoice_data(text):\n    prompt = f\"\"\"\nYou are a model designed to extract invoice information. Please strictly extract and return the invoice information in the following JSON format, and nothing else:\n\nJSON Format:\n{{\n    \"Invoice Number\": \"\",\n    \"Invoice Date\": \"\",\n    \"Due Date\": \"\",\n    \"Total Amount\": \"\",\n    \"Vendor Name\": \"\",\n    \"Vendor Address\": \"\",\n    \"Buyer Name\": \"\",\n    \"Buyer Address\": \"\",\n    \"GSTIN Number\": \"\",\n    \"Bank Details\": {{\n        \"Name\": \"\",\n        \"Account Number\": \"\",\n        \"IFSC Code\": \"\"\n    }},\n    \"Payment Terms\": \"\"\n}}\n\nExtract the information strictly from the invoice text provided below:\n\n\\\"\\\"\\\" \n{text} \n\\\"\\\"\\\"\n\nEnsure that the JSON is valid and strictly adheres to the format. Return no additional explanations.\n\"\"\"\n\n    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n    outputs = model.generate(**inputs, max_length=2048, temperature=0.0, stop_token=None)\n    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n    return response\n","metadata":{"execution":{"iopub.status.busy":"2024-10-12T08:31:58.673489Z","iopub.execute_input":"2024-10-12T08:31:58.676085Z","iopub.status.idle":"2024-10-12T08:31:58.693210Z","shell.execute_reply.started":"2024-10-12T08:31:58.675973Z","shell.execute_reply":"2024-10-12T08:31:58.691014Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"# Install necessary packages\n!pip install pdfplumber pdf2image pytesseract transformers accelerate sentencepiece ipywidgets\n\n# Import Libraries\nimport os\nimport pdfplumber\nfrom pdf2image import convert_from_path\nimport pytesseract\nfrom PIL import Image\nimport tempfile\nimport re\nimport json\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\nimport torch\nimport ipywidgets as widgets\nfrom IPython.display import display, clear_output\n","metadata":{"execution":{"iopub.status.busy":"2024-10-12T10:21:12.317465Z","iopub.execute_input":"2024-10-12T10:21:12.317898Z","iopub.status.idle":"2024-10-12T10:21:25.030623Z","shell.execute_reply.started":"2024-10-12T10:21:12.317858Z","shell.execute_reply":"2024-10-12T10:21:25.029576Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: pdfplumber in /opt/conda/lib/python3.10/site-packages (0.11.4)\nRequirement already satisfied: pdf2image in /opt/conda/lib/python3.10/site-packages (1.17.0)\nRequirement already satisfied: pytesseract in /opt/conda/lib/python3.10/site-packages (0.3.13)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.45.1)\nRequirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (0.34.2)\nRequirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (0.2.0)\nRequirement already satisfied: ipywidgets in /opt/conda/lib/python3.10/site-packages (7.7.1)\nRequirement already satisfied: pdfminer.six==20231228 in /opt/conda/lib/python3.10/site-packages (from pdfplumber) (20231228)\nRequirement already satisfied: Pillow>=9.1 in /opt/conda/lib/python3.10/site-packages (from pdfplumber) (10.3.0)\nRequirement already satisfied: pypdfium2>=4.18.0 in /opt/conda/lib/python3.10/site-packages (from pdfplumber) (4.30.0)\nRequirement already satisfied: charset-normalizer>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from pdfminer.six==20231228->pdfplumber) (3.3.2)\nRequirement already satisfied: cryptography>=36.0.0 in /opt/conda/lib/python3.10/site-packages (from pdfminer.six==20231228->pdfplumber) (42.0.8)\nRequirement already satisfied: packaging>=21.3 in /opt/conda/lib/python3.10/site-packages (from pytesseract) (21.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.15.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.25.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.5.15)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.5)\nRequirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.20.0)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.3)\nRequirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (2.4.0)\nRequirement already satisfied: ipykernel>=4.5.1 in /opt/conda/lib/python3.10/site-packages (from ipywidgets) (6.29.4)\nRequirement already satisfied: ipython-genutils~=0.2.0 in /opt/conda/lib/python3.10/site-packages (from ipywidgets) (0.2.0)\nRequirement already satisfied: traitlets>=4.3.1 in /opt/conda/lib/python3.10/site-packages (from ipywidgets) (5.14.3)\nRequirement already satisfied: widgetsnbextension~=3.6.0 in /opt/conda/lib/python3.10/site-packages (from ipywidgets) (3.6.9)\nRequirement already satisfied: ipython>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from ipywidgets) (8.21.0)\nRequirement already satisfied: jupyterlab-widgets>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from ipywidgets) (3.0.11)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\nRequirement already satisfied: comm>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets) (0.2.2)\nRequirement already satisfied: debugpy>=1.6.5 in /opt/conda/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets) (1.8.1)\nRequirement already satisfied: jupyter-client>=6.1.12 in /opt/conda/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets) (7.4.9)\nRequirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /opt/conda/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets) (5.7.2)\nRequirement already satisfied: matplotlib-inline>=0.1 in /opt/conda/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets) (0.1.7)\nRequirement already satisfied: nest-asyncio in /opt/conda/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets) (1.6.0)\nRequirement already satisfied: pyzmq>=24 in /opt/conda/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets) (26.0.3)\nRequirement already satisfied: tornado>=6.1 in /opt/conda/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets) (6.4.1)\nRequirement already satisfied: decorator in /opt/conda/lib/python3.10/site-packages (from ipython>=4.0.0->ipywidgets) (5.1.1)\nRequirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.10/site-packages (from ipython>=4.0.0->ipywidgets) (0.19.1)\nRequirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /opt/conda/lib/python3.10/site-packages (from ipython>=4.0.0->ipywidgets) (3.0.47)\nRequirement already satisfied: pygments>=2.4.0 in /opt/conda/lib/python3.10/site-packages (from ipython>=4.0.0->ipywidgets) (2.18.0)\nRequirement already satisfied: stack-data in /opt/conda/lib/python3.10/site-packages (from ipython>=4.0.0->ipywidgets) (0.6.2)\nRequirement already satisfied: exceptiongroup in /opt/conda/lib/python3.10/site-packages (from ipython>=4.0.0->ipywidgets) (1.2.0)\nRequirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.10/site-packages (from ipython>=4.0.0->ipywidgets) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=21.3->pytesseract) (3.1.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.4)\nRequirement already satisfied: notebook>=4.4.1 in /opt/conda/lib/python3.10/site-packages (from widgetsnbextension~=3.6.0->ipywidgets) (6.5.7)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.8.30)\nRequirement already satisfied: cffi>=1.12 in /opt/conda/lib/python3.10/site-packages (from cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (1.16.0)\nRequirement already satisfied: parso<0.9.0,>=0.8.3 in /opt/conda/lib/python3.10/site-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets) (0.8.4)\nRequirement already satisfied: entrypoints in /opt/conda/lib/python3.10/site-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (0.4)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (2.9.0.post0)\nRequirement already satisfied: platformdirs>=2.5 in /opt/conda/lib/python3.10/site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel>=4.5.1->ipywidgets) (3.11.0)\nRequirement already satisfied: argon2-cffi in /opt/conda/lib/python3.10/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (23.1.0)\nRequirement already satisfied: nbformat in /opt/conda/lib/python3.10/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (5.10.4)\nRequirement already satisfied: nbconvert>=5 in /opt/conda/lib/python3.10/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (6.4.5)\nRequirement already satisfied: Send2Trash>=1.8.0 in /opt/conda/lib/python3.10/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.8.3)\nRequirement already satisfied: terminado>=0.8.3 in /opt/conda/lib/python3.10/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.18.1)\nRequirement already satisfied: prometheus-client in /opt/conda/lib/python3.10/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.20.0)\nRequirement already satisfied: nbclassic>=0.4.7 in /opt/conda/lib/python3.10/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.1.0)\nRequirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.10/site-packages (from pexpect>4.3->ipython>=4.0.0->ipywidgets) (0.7.0)\nRequirement already satisfied: wcwidth in /opt/conda/lib/python3.10/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=4.0.0->ipywidgets) (0.2.13)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\nRequirement already satisfied: executing>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython>=4.0.0->ipywidgets) (2.0.1)\nRequirement already satisfied: asttokens>=2.1.0 in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython>=4.0.0->ipywidgets) (2.4.1)\nRequirement already satisfied: pure-eval in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython>=4.0.0->ipywidgets) (0.2.2)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\nRequirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from asttokens>=2.1.0->stack-data->ipython>=4.0.0->ipywidgets) (1.16.0)\nRequirement already satisfied: pycparser in /opt/conda/lib/python3.10/site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (2.22)\nRequirement already satisfied: notebook-shim>=0.2.3 in /opt/conda/lib/python3.10/site-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.2.4)\nRequirement already satisfied: mistune<2,>=0.8.1 in /opt/conda/lib/python3.10/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.8.4)\nRequirement already satisfied: jupyterlab-pygments in /opt/conda/lib/python3.10/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.3.0)\nRequirement already satisfied: bleach in /opt/conda/lib/python3.10/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (6.1.0)\nRequirement already satisfied: pandocfilters>=1.4.1 in /opt/conda/lib/python3.10/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.5.0)\nRequirement already satisfied: testpath in /opt/conda/lib/python3.10/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.6.0)\nRequirement already satisfied: defusedxml in /opt/conda/lib/python3.10/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.7.1)\nRequirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.10/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.12.3)\nRequirement already satisfied: nbclient<0.6.0,>=0.5.0 in /opt/conda/lib/python3.10/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.5.13)\nRequirement already satisfied: fastjsonschema>=2.15 in /opt/conda/lib/python3.10/site-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.19.1)\nRequirement already satisfied: jsonschema>=2.6 in /opt/conda/lib/python3.10/site-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.22.0)\nRequirement already satisfied: argon2-cffi-bindings in /opt/conda/lib/python3.10/site-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (21.2.0)\nRequirement already satisfied: attrs>=22.2.0 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (23.2.0)\nRequirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2023.12.1)\nRequirement already satisfied: referencing>=0.28.4 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.35.1)\nRequirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.18.1)\nRequirement already satisfied: jupyter-server<3,>=1.8 in /opt/conda/lib/python3.10/site-packages (from notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.12.5)\nRequirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.5)\nRequirement already satisfied: webencodings in /opt/conda/lib/python3.10/site-packages (from bleach->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.5.1)\nRequirement already satisfied: anyio>=3.1.0 in /opt/conda/lib/python3.10/site-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.4.0)\nRequirement already satisfied: jupyter-events>=0.9.0 in /opt/conda/lib/python3.10/site-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.10.0)\nRequirement already satisfied: jupyter-server-terminals in /opt/conda/lib/python3.10/site-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.5.3)\nRequirement already satisfied: overrides in /opt/conda/lib/python3.10/site-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (7.7.0)\nRequirement already satisfied: websocket-client in /opt/conda/lib/python3.10/site-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.8.0)\nRequirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.10/site-packages (from anyio>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.3.1)\nRequirement already satisfied: python-json-logger>=2.0.4 in /opt/conda/lib/python3.10/site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.0.7)\nRequirement already satisfied: rfc3339-validator in /opt/conda/lib/python3.10/site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.1.4)\nRequirement already satisfied: rfc3986-validator>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.1.1)\nRequirement already satisfied: fqdn in /opt/conda/lib/python3.10/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.5.1)\nRequirement already satisfied: isoduration in /opt/conda/lib/python3.10/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (20.11.0)\nRequirement already satisfied: jsonpointer>1.13 in /opt/conda/lib/python3.10/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.4)\nRequirement already satisfied: uri-template in /opt/conda/lib/python3.10/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.3.0)\nRequirement already satisfied: webcolors>=1.11 in /opt/conda/lib/python3.10/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (24.6.0)\nRequirement already satisfied: arrow>=0.15.0 in /opt/conda/lib/python3.10/site-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.3.0)\nRequirement already satisfied: types-python-dateutil>=2.8.10 in /opt/conda/lib/python3.10/site-packages (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.9.0.20240316)\n","output_type":"stream"}]},{"cell_type":"code","source":"!which tesseract\n","metadata":{"execution":{"iopub.status.busy":"2024-10-12T10:05:38.560017Z","iopub.execute_input":"2024-10-12T10:05:38.560504Z","iopub.status.idle":"2024-10-12T10:05:39.619155Z","shell.execute_reply.started":"2024-10-12T10:05:38.560466Z","shell.execute_reply":"2024-10-12T10:05:39.617910Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"/usr/bin/tesseract\n","output_type":"stream"}]},{"cell_type":"code","source":"# Check if Tesseract is installed\ntesseract_path = !which tesseract\nif tesseract_path:\n    print(f\"Tesseract is installed at: {tesseract_path[0]}\")\nelse:\n    print(\"Tesseract is not installed. Attempting to install...\")\n    # Uncomment the following line if Tesseract is not installed and if Kaggle permits\n    # !apt-get install -y tesseract-ocr\n    print(\"Please install Tesseract OCR manually or ensure it's available in the environment.\")\n","metadata":{"execution":{"iopub.status.busy":"2024-10-12T10:21:37.732309Z","iopub.execute_input":"2024-10-12T10:21:37.732732Z","iopub.status.idle":"2024-10-12T10:21:37.746244Z","shell.execute_reply.started":"2024-10-12T10:21:37.732691Z","shell.execute_reply":"2024-10-12T10:21:37.745173Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"Tesseract is installed at: /usr/bin/tesseract\n","output_type":"stream"}]},{"cell_type":"code","source":"# Initialize Hugging Face model\ndef load_hf_model():\n    # Choose a smaller model to fit within GPU memory limits\n    model_path = \"facebook/opt-6.7b\"  # You can change this to another smaller model if needed\n    \n    try:\n        print(\"Loading tokenizer...\")\n        tokenizer = AutoTokenizer.from_pretrained(model_path)\n        print(\"Tokenizer loaded successfully.\")\n        \n        print(\"Loading model...\")\n        model = AutoModelForCausalLM.from_pretrained(\n            model_path,\n            device_map=\"auto\",\n            torch_dtype=torch.float16,\n            # load_in_8bit=True  # Uncomment if using 8-bit precision and supported\n        )\n        print(\"Model loaded successfully.\")\n        return tokenizer, model\n    except Exception as e:\n        print(f\"Error loading model: {e}\")\n        return None, None\n\n# Load the model\ntokenizer, model = load_hf_model()\n\n# Verify model loading\nif model is not None and tokenizer is not None:\n    print(\"Model and tokenizer are ready for use.\")\nelse:\n    print(\"Model and/or tokenizer failed to load. Please check the model path and format.\")\n","metadata":{"execution":{"iopub.status.busy":"2024-10-12T10:21:50.199041Z","iopub.execute_input":"2024-10-12T10:21:50.200011Z","iopub.status.idle":"2024-10-12T10:24:00.219318Z","shell.execute_reply.started":"2024-10-12T10:21:50.199959Z","shell.execute_reply":"2024-10-12T10:24:00.218173Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"Loading tokenizer...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/685 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7ee09a24828844db9d2bc06d00867e3b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/651 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"959a8b30f207467ca9b7985033293d97"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aa6756a065804cbd9b6ef2eb4f54deca"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"564c055b94f74b888ad1f4d32b22766f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/441 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"302ff7e58d744f7183cf2585a9d765c0"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Tokenizer loaded successfully.\nLoading model...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin.index.json:   0%|          | 0.00/41.9k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0f65e2d3acd44459a56ce545b927cb3b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b02b2594236e465cb3e37b5b8f23d45c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model-00001-of-00002.bin:   0%|          | 0.00/9.96G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8f0aacf64ab643bd9fb6a0e1f86305df"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model-00002-of-00002.bin:   0%|          | 0.00/3.36G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"131c8ba26c7d4af3be5d326a474b4c9b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ef4a8ab67fb44a28b8924599fa193cc7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/137 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8092c8e9e9914e5691ed0db660bbf674"}},"metadata":{}},{"name":"stdout","text":"Model loaded successfully.\nModel and tokenizer are ready for use.\n","output_type":"stream"}]},{"cell_type":"code","source":"# Initialize Hugging Face model\ndef load_hf_model():\n    model_path = \"/kaggle/input/llama-3/transformers/8b-chat-hf/1\"  # Update as necessary\n    try:\n        print(\"Loading tokenizer...\")\n        tokenizer = AutoTokenizer.from_pretrained(model_path)\n        print(\"Tokenizer loaded successfully.\")\n        \n        print(\"Loading model...\")\n        model = AutoModelForCausalLM.from_pretrained(\n            model_path,\n            device_map=\"auto\",\n            torch_dtype=torch.float16,\n            # load_in_8bit=True  # Uncomment if using 8-bit precision and supported\n        )\n        print(\"Model loaded successfully.\")\n        return tokenizer, model\n    except Exception as e:\n        print(f\"Error loading model: {e}\")\n        return None, None\n\n# Load the model\ntokenizer, model = load_hf_model()\n\n# Verify model loading\nif model is not None and tokenizer is not None:\n    print(\"Model and tokenizer are ready for use.\")\nelse:\n    print(\"Model and/or tokenizer failed to load. Please check the model path and format.\")\n","metadata":{"execution":{"iopub.status.busy":"2024-10-12T10:13:51.569045Z","iopub.execute_input":"2024-10-12T10:13:51.569455Z","iopub.status.idle":"2024-10-12T10:14:07.968254Z","shell.execute_reply.started":"2024-10-12T10:13:51.569415Z","shell.execute_reply":"2024-10-12T10:14:07.967263Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Loading tokenizer...\nTokenizer loaded successfully.\nLoading model...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a4d15f19f4724ffeb1f476f3f7dc7d1b"}},"metadata":{}},{"name":"stdout","text":"Model loaded successfully.\nModel and tokenizer are ready for use.\n","output_type":"stream"}]},{"cell_type":"code","source":"def extract_text_from_pdf(file_path):\n    \"\"\"\n    Extracts selectable text from a PDF file using pdfplumber.\n    \"\"\"\n    text = \"\"\n    try:\n        with pdfplumber.open(file_path) as pdf:\n            for page_number, page in enumerate(pdf.pages, start=1):\n                extracted = page.extract_text()\n                if extracted:\n                    text += extracted + \"\\n\"\n                else:\n                    print(f\"No selectable text found on page {page_number}.\")\n    except Exception as e:\n        print(f\"Error reading PDF: {e}\")\n        return \"\"\n    return text\n\ndef extract_text_via_ocr(file_path):\n    \"\"\"\n    Extracts text from a PDF file using OCR (pytesseract) after converting PDF pages to images.\n    \"\"\"\n    text = \"\"\n    with tempfile.TemporaryDirectory() as path:\n        try:\n            print(\"Converting PDF pages to images for OCR...\")\n            images = convert_from_path(file_path, output_folder=path, fmt='png')\n            print(f\"Converted PDF to {len(images)} image(s).\")\n        except Exception as e:\n            print(f\"Error converting PDF to images: {e}\")\n            return \"\"\n        for idx, img in enumerate(images, start=1):\n            try:\n                print(f\"Performing OCR on page {idx}...\")\n                ocr_text = pytesseract.image_to_string(img)\n                if ocr_text.strip():\n                    text += ocr_text + \"\\n\"\n                else:\n                    print(f\"No text found via OCR on page {idx}.\")\n            except Exception as e:\n                print(f\"Error with OCR on image page {idx}: {e}\")\n                return \"\"\n    return text\n\ndef preprocess_text(text):\n    \"\"\"\n    Cleans the extracted text by removing excessive whitespace and unwanted characters.\n    \"\"\"\n    # Remove multiple spaces, newlines, and tabs\n    text = re.sub(r'\\s+', ' ', text)\n    # Optionally, remove non-ASCII characters\n    text = re.sub(r'[^\\x00-\\x7F]+', ' ', text)\n    return text.strip()\n\ndef extract_invoice_data(text, tokenizer, model):\n    \"\"\"\n    Uses the Hugging Face model to extract structured invoice data from text.\n    \"\"\"\n    prompt = f\"\"\"\nYou are an AI assistant specialized in extracting invoice information. Please strictly extract and return the invoice information in the following JSON format, and nothing else:\n\nJSON Format:\n{{\n    \"Invoice Number\": \"\",\n    \"Invoice Date\": \"\",\n    \"Due Date\": \"\",\n    \"Total Amount\": \"\",\n    \"Vendor Name\": \"\",\n    \"Vendor Address\": \"\",\n    \"Buyer Name\": \"\",\n    \"Buyer Address\": \"\",\n    \"GSTIN Number\": \"\",\n    \"Bank Details\": {{\n        \"Name\": \"\",\n        \"Account Number\": \"\",\n        \"IFSC Code\": \"\"\n    }},\n    \"Payment Terms\": \"\"\n}}\n\nExtract the information strictly from the invoice text provided below:\n\n\\\"\\\"\\\"\n{text}\n\\\"\\\"\\\"\n\nEnsure that the JSON is valid and strictly adheres to the format. Do not include any explanations or additional text.\n\"\"\"\n\n    try:\n        print(\"Tokenizing input...\")\n        inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n        print(\"Generating model response...\")\n        with torch.no_grad():\n            outputs = model.generate(\n                **inputs,\n                max_length=2048,\n                temperature=0.0,\n                do_sample=False,\n                eos_token_id=tokenizer.eos_token_id\n            )\n        response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n        print(\"Model response generated.\")\n        return response\n    except Exception as e:\n        print(f\"Error during model inference: {e}\")\n        return \"\"\n\ndef parse_json(text):\n    \"\"\"\n    Parses JSON text extracted from the model's response.\n    \"\"\"\n    try:\n        # Use regex to find the first JSON-like structure\n        json_text_match = re.search(r'\\{.*\\}', text, re.DOTALL)\n        if json_text_match:\n            json_text = json_text_match.group()\n            # Try loading the JSON\n            data = json.loads(json_text)\n            return data\n        else:\n            raise ValueError(\"No valid JSON found in the text.\")\n    except json.JSONDecodeError as e:\n        print(f\"JSON decode error: {e}\")\n        return None\n    except Exception as e:\n        print(f\"Failed to parse JSON: {e}\")\n        return None\n","metadata":{"execution":{"iopub.status.busy":"2024-10-12T10:37:17.492503Z","iopub.execute_input":"2024-10-12T10:37:17.493210Z","iopub.status.idle":"2024-10-12T10:37:17.512291Z","shell.execute_reply.started":"2024-10-12T10:37:17.493168Z","shell.execute_reply":"2024-10-12T10:37:17.511331Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"# Create a file uploader widget\nuploader = widgets.FileUpload(\n    accept='.pdf',  # Accept only PDF files\n    multiple=False,  # Allow single file upload\n    description='Upload PDF',\n    button_style='info',  # 'success', 'info', 'warning', 'danger' or ''\n    style={'description_width': 'initial'},\n)\n\n# Create a button to trigger processing\nprocess_button = widgets.Button(\n    description=\"Process Uploaded PDF\",\n    button_style='success',  # 'success', 'info', 'warning', 'danger' or ''\n    tooltip='Click to process the uploaded PDF file',\n    icon='check'  # (FontAwesome names without the `fa-` prefix)\n)\n\n# Display the uploader and the button\ndisplay(uploader, process_button)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-12T10:37:18.353982Z","iopub.execute_input":"2024-10-12T10:37:18.354390Z","iopub.status.idle":"2024-10-12T10:37:18.368994Z","shell.execute_reply.started":"2024-10-12T10:37:18.354351Z","shell.execute_reply":"2024-10-12T10:37:18.368144Z"},"trusted":true},"execution_count":35,"outputs":[{"output_type":"display_data","data":{"text/plain":"FileUpload(value={}, accept='.pdf', button_style='info', description='Upload PDF')","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f9f1a273f5c343e0abb5d6e6a9774e7e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Button(button_style='success', description='Process Uploaded PDF', icon='check', style=ButtonStyle(), tooltip=‚Ä¶","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"766973ee7f074e5ea8408b45e8fb9eb8"}},"metadata":{}}]},{"cell_type":"code","source":"def process_uploaded_file(uploader_widget, tokenizer, model):\n    \"\"\"\n    Processes the uploaded PDF file: extracts text, performs OCR if needed, and extracts invoice data.\n    \"\"\"\n    if not uploader_widget.value:\n        print(\"No file uploaded yet. Please upload a PDF file to proceed.\")\n        return\n    \n    # Retrieve the uploaded file\n    uploaded_filename = list(uploader_widget.value.keys())[0]\n    uploaded_file = uploader_widget.value[uploaded_filename]\n    file_content = uploaded_file['content']\n    \n    # Save the uploaded file to a temporary file\n    try:\n        with tempfile.NamedTemporaryFile(delete=False, suffix=\".pdf\") as tmp_file:\n            tmp_file.write(file_content)\n            tmp_file_path = tmp_file.name\n        print(f\"\\nSaved uploaded file as temporary file: {tmp_file_path}\")\n    except Exception as e:\n        print(f\"Error saving uploaded file: {e}\")\n        return\n    \n    print(f\"\\nProcessing file: {uploaded_filename}\")\n    \n    # Attempt to extract text directly\n    print(\"\\n--- Step 1: Extracting Text Using pdfplumber ---\")\n    text = extract_text_from_pdf(tmp_file_path)\n    \n    # If no text found, perform OCR\n    if not text.strip():\n        print(\"\\n--- Step 2: No Text Found via pdfplumber. Performing OCR ---\")\n        text = extract_text_via_ocr(tmp_file_path)\n    \n    # Preprocess the text\n    print(\"\\n--- Step 3: Preprocessing Extracted Text ---\")\n    text = preprocess_text(text)\n    \n    if not text.strip():\n        print(\"Failed to extract text from the PDF after both extraction methods.\")\n        return\n    else:\n        print(\"\\n--- Extracted Text (First 1000 characters) ---\\n\")\n        print(text[:1000] + ('...' if len(text) > 1000 else ''))\n    \n    # Extract structured data using Hugging Face model\n    print(\"\\n--- Step 4: Extracting Structured Invoice Data Using Model ---\\n\")\n    model_response = extract_invoice_data(text, tokenizer, model)\n    \n    if not model_response:\n        print(\"Model inference failed or returned an empty response.\")\n        return\n    else:\n        # Debugging: Display the raw model response\n        print(\"\\n--- Model Response (Debug) ---\\n\")\n        print(model_response)\n    \n        # Parse the JSON from the response\n        print(\"\\n--- Step 5: Parsing JSON from Model Response ---\\n\")\n        extracted_data = parse_json(model_response)\n    \n        if extracted_data:\n            print(\"\\n--- Extracted Invoice Data ---\\n\")\n            print(json.dumps(extracted_data, indent=4))\n        else:\n            print(\"Failed to parse extracted data from the model response.\")\n","metadata":{"execution":{"iopub.status.busy":"2024-10-12T10:35:25.237743Z","iopub.execute_input":"2024-10-12T10:35:25.238781Z","iopub.status.idle":"2024-10-12T10:35:25.251659Z","shell.execute_reply.started":"2024-10-12T10:35:25.238736Z","shell.execute_reply":"2024-10-12T10:35:25.250170Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"# Define the button's click event handler\ndef on_process_button_clicked(b):\n    # Optionally, clear previous outputs if desired\n    # clear_output(wait=True)\n    print(\"\\nButton clicked. Starting processing...\\n\")\n    process_uploaded_file(uploader, tokenizer, model)\n\n# Link the button to the event handler\nprocess_button.on_click(on_process_button_clicked)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-12T10:24:02.576155Z","iopub.execute_input":"2024-10-12T10:24:02.576588Z","iopub.status.idle":"2024-10-12T10:24:02.675674Z","shell.execute_reply.started":"2024-10-12T10:24:02.576535Z","shell.execute_reply":"2024-10-12T10:24:02.674637Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Install necessary packages\n!pip install pdfplumber pdf2image pytesseract pillow ipywidgets llama-cpp-python\n\n# Install Tesseract OCR\n!apt-get install -y tesseract-ocr\n","metadata":{"execution":{"iopub.status.busy":"2024-10-12T12:47:11.229265Z","iopub.execute_input":"2024-10-12T12:47:11.229799Z","iopub.status.idle":"2024-10-12T12:47:26.359816Z","shell.execute_reply.started":"2024-10-12T12:47:11.229756Z","shell.execute_reply":"2024-10-12T12:47:26.358676Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Requirement already satisfied: pdfplumber in /opt/conda/lib/python3.10/site-packages (0.11.4)\nRequirement already satisfied: pdf2image in /opt/conda/lib/python3.10/site-packages (1.17.0)\nRequirement already satisfied: pytesseract in /opt/conda/lib/python3.10/site-packages (0.3.13)\nRequirement already satisfied: pillow in /opt/conda/lib/python3.10/site-packages (10.3.0)\nRequirement already satisfied: ipywidgets in /opt/conda/lib/python3.10/site-packages (7.7.1)\nRequirement already satisfied: llama-cpp-python in /opt/conda/lib/python3.10/site-packages (0.3.1)\nRequirement already satisfied: pdfminer.six==20231228 in /opt/conda/lib/python3.10/site-packages (from pdfplumber) (20231228)\nRequirement already satisfied: pypdfium2>=4.18.0 in /opt/conda/lib/python3.10/site-packages (from pdfplumber) (4.30.0)\nRequirement already satisfied: charset-normalizer>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from pdfminer.six==20231228->pdfplumber) (3.3.2)\nRequirement already satisfied: cryptography>=36.0.0 in /opt/conda/lib/python3.10/site-packages (from pdfminer.six==20231228->pdfplumber) (42.0.8)\nRequirement already satisfied: packaging>=21.3 in /opt/conda/lib/python3.10/site-packages (from pytesseract) (21.3)\nRequirement already satisfied: ipykernel>=4.5.1 in /opt/conda/lib/python3.10/site-packages (from ipywidgets) (6.29.4)\nRequirement already satisfied: ipython-genutils~=0.2.0 in /opt/conda/lib/python3.10/site-packages (from ipywidgets) (0.2.0)\nRequirement already satisfied: traitlets>=4.3.1 in /opt/conda/lib/python3.10/site-packages (from ipywidgets) (5.14.3)\nRequirement already satisfied: widgetsnbextension~=3.6.0 in /opt/conda/lib/python3.10/site-packages (from ipywidgets) (3.6.9)\nRequirement already satisfied: ipython>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from ipywidgets) (8.21.0)\nRequirement already satisfied: jupyterlab-widgets>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from ipywidgets) (3.0.11)\nRequirement already satisfied: typing-extensions>=4.5.0 in /opt/conda/lib/python3.10/site-packages (from llama-cpp-python) (4.12.2)\nRequirement already satisfied: numpy>=1.20.0 in /opt/conda/lib/python3.10/site-packages (from llama-cpp-python) (1.26.4)\nRequirement already satisfied: diskcache>=5.6.1 in /opt/conda/lib/python3.10/site-packages (from llama-cpp-python) (5.6.3)\nRequirement already satisfied: jinja2>=2.11.3 in /opt/conda/lib/python3.10/site-packages (from llama-cpp-python) (3.1.4)\nRequirement already satisfied: comm>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets) (0.2.2)\nRequirement already satisfied: debugpy>=1.6.5 in /opt/conda/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets) (1.8.1)\nRequirement already satisfied: jupyter-client>=6.1.12 in /opt/conda/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets) (7.4.9)\nRequirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /opt/conda/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets) (5.7.2)\nRequirement already satisfied: matplotlib-inline>=0.1 in /opt/conda/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets) (0.1.7)\nRequirement already satisfied: nest-asyncio in /opt/conda/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets) (1.6.0)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets) (5.9.3)\nRequirement already satisfied: pyzmq>=24 in /opt/conda/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets) (26.0.3)\nRequirement already satisfied: tornado>=6.1 in /opt/conda/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets) (6.4.1)\nRequirement already satisfied: decorator in /opt/conda/lib/python3.10/site-packages (from ipython>=4.0.0->ipywidgets) (5.1.1)\nRequirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.10/site-packages (from ipython>=4.0.0->ipywidgets) (0.19.1)\nRequirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /opt/conda/lib/python3.10/site-packages (from ipython>=4.0.0->ipywidgets) (3.0.47)\nRequirement already satisfied: pygments>=2.4.0 in /opt/conda/lib/python3.10/site-packages (from ipython>=4.0.0->ipywidgets) (2.18.0)\nRequirement already satisfied: stack-data in /opt/conda/lib/python3.10/site-packages (from ipython>=4.0.0->ipywidgets) (0.6.2)\nRequirement already satisfied: exceptiongroup in /opt/conda/lib/python3.10/site-packages (from ipython>=4.0.0->ipywidgets) (1.2.0)\nRequirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.10/site-packages (from ipython>=4.0.0->ipywidgets) (4.9.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2>=2.11.3->llama-cpp-python) (2.1.5)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=21.3->pytesseract) (3.1.2)\nRequirement already satisfied: notebook>=4.4.1 in /opt/conda/lib/python3.10/site-packages (from widgetsnbextension~=3.6.0->ipywidgets) (6.5.7)\nRequirement already satisfied: cffi>=1.12 in /opt/conda/lib/python3.10/site-packages (from cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (1.16.0)\nRequirement already satisfied: parso<0.9.0,>=0.8.3 in /opt/conda/lib/python3.10/site-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets) (0.8.4)\nRequirement already satisfied: entrypoints in /opt/conda/lib/python3.10/site-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (0.4)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (2.9.0.post0)\nRequirement already satisfied: platformdirs>=2.5 in /opt/conda/lib/python3.10/site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel>=4.5.1->ipywidgets) (3.11.0)\nRequirement already satisfied: argon2-cffi in /opt/conda/lib/python3.10/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (23.1.0)\nRequirement already satisfied: nbformat in /opt/conda/lib/python3.10/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (5.10.4)\nRequirement already satisfied: nbconvert>=5 in /opt/conda/lib/python3.10/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (6.4.5)\nRequirement already satisfied: Send2Trash>=1.8.0 in /opt/conda/lib/python3.10/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.8.3)\nRequirement already satisfied: terminado>=0.8.3 in /opt/conda/lib/python3.10/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.18.1)\nRequirement already satisfied: prometheus-client in /opt/conda/lib/python3.10/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.20.0)\nRequirement already satisfied: nbclassic>=0.4.7 in /opt/conda/lib/python3.10/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.1.0)\nRequirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.10/site-packages (from pexpect>4.3->ipython>=4.0.0->ipywidgets) (0.7.0)\nRequirement already satisfied: wcwidth in /opt/conda/lib/python3.10/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=4.0.0->ipywidgets) (0.2.13)\nRequirement already satisfied: executing>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython>=4.0.0->ipywidgets) (2.0.1)\nRequirement already satisfied: asttokens>=2.1.0 in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython>=4.0.0->ipywidgets) (2.4.1)\nRequirement already satisfied: pure-eval in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython>=4.0.0->ipywidgets) (0.2.2)\nRequirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from asttokens>=2.1.0->stack-data->ipython>=4.0.0->ipywidgets) (1.16.0)\nRequirement already satisfied: pycparser in /opt/conda/lib/python3.10/site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (2.22)\nRequirement already satisfied: notebook-shim>=0.2.3 in /opt/conda/lib/python3.10/site-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.2.4)\nRequirement already satisfied: mistune<2,>=0.8.1 in /opt/conda/lib/python3.10/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.8.4)\nRequirement already satisfied: jupyterlab-pygments in /opt/conda/lib/python3.10/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.3.0)\nRequirement already satisfied: bleach in /opt/conda/lib/python3.10/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (6.1.0)\nRequirement already satisfied: pandocfilters>=1.4.1 in /opt/conda/lib/python3.10/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.5.0)\nRequirement already satisfied: testpath in /opt/conda/lib/python3.10/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.6.0)\nRequirement already satisfied: defusedxml in /opt/conda/lib/python3.10/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.7.1)\nRequirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.10/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.12.3)\nRequirement already satisfied: nbclient<0.6.0,>=0.5.0 in /opt/conda/lib/python3.10/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.5.13)\nRequirement already satisfied: fastjsonschema>=2.15 in /opt/conda/lib/python3.10/site-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.19.1)\nRequirement already satisfied: jsonschema>=2.6 in /opt/conda/lib/python3.10/site-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.22.0)\nRequirement already satisfied: argon2-cffi-bindings in /opt/conda/lib/python3.10/site-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (21.2.0)\nRequirement already satisfied: attrs>=22.2.0 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (23.2.0)\nRequirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2023.12.1)\nRequirement already satisfied: referencing>=0.28.4 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.35.1)\nRequirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.18.1)\nRequirement already satisfied: jupyter-server<3,>=1.8 in /opt/conda/lib/python3.10/site-packages (from notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.12.5)\nRequirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.5)\nRequirement already satisfied: webencodings in /opt/conda/lib/python3.10/site-packages (from bleach->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.5.1)\nRequirement already satisfied: anyio>=3.1.0 in /opt/conda/lib/python3.10/site-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.4.0)\nRequirement already satisfied: jupyter-events>=0.9.0 in /opt/conda/lib/python3.10/site-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.10.0)\nRequirement already satisfied: jupyter-server-terminals in /opt/conda/lib/python3.10/site-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.5.3)\nRequirement already satisfied: overrides in /opt/conda/lib/python3.10/site-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (7.7.0)\nRequirement already satisfied: websocket-client in /opt/conda/lib/python3.10/site-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.8.0)\nRequirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.10/site-packages (from anyio>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.7)\nRequirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.10/site-packages (from anyio>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.3.1)\nRequirement already satisfied: python-json-logger>=2.0.4 in /opt/conda/lib/python3.10/site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.0.7)\nRequirement already satisfied: pyyaml>=5.3 in /opt/conda/lib/python3.10/site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (6.0.2)\nRequirement already satisfied: rfc3339-validator in /opt/conda/lib/python3.10/site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.1.4)\nRequirement already satisfied: rfc3986-validator>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.1.1)\nRequirement already satisfied: fqdn in /opt/conda/lib/python3.10/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.5.1)\nRequirement already satisfied: isoduration in /opt/conda/lib/python3.10/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (20.11.0)\nRequirement already satisfied: jsonpointer>1.13 in /opt/conda/lib/python3.10/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.4)\nRequirement already satisfied: uri-template in /opt/conda/lib/python3.10/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.3.0)\nRequirement already satisfied: webcolors>=1.11 in /opt/conda/lib/python3.10/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (24.6.0)\nRequirement already satisfied: arrow>=0.15.0 in /opt/conda/lib/python3.10/site-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.3.0)\nRequirement already satisfied: types-python-dateutil>=2.8.10 in /opt/conda/lib/python3.10/site-packages (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.9.0.20240316)\nReading package lists... Done\nBuilding dependency tree... Done\nReading state information... Done\ntesseract-ocr is already the newest version (4.1.1-2.1build1).\n0 upgraded, 0 newly installed, 0 to remove and 68 not upgraded.\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nimport pdfplumber\nfrom pdf2image import convert_from_path\nimport pytesseract\nfrom PIL import Image\nimport tempfile\nimport re\nimport json\nfrom llama_cpp import Llama\nimport ipywidgets as widgets\nfrom IPython.display import display, clear_output\n","metadata":{"execution":{"iopub.status.busy":"2024-10-12T12:47:33.134461Z","iopub.execute_input":"2024-10-12T12:47:33.134880Z","iopub.status.idle":"2024-10-12T12:47:33.385661Z","shell.execute_reply.started":"2024-10-12T12:47:33.134839Z","shell.execute_reply":"2024-10-12T12:47:33.384897Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"!pip install transformers\n","metadata":{"execution":{"iopub.status.busy":"2024-10-12T12:53:17.975628Z","iopub.execute_input":"2024-10-12T12:53:17.976563Z","iopub.status.idle":"2024-10-12T12:53:29.743899Z","shell.execute_reply.started":"2024-10-12T12:53:17.976520Z","shell.execute_reply":"2024-10-12T12:53:29.742684Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.45.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.15.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.25.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.5.15)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.5)\nRequirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.20.0)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.8.30)\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nimport torch\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\n\ndef load_llama_model():\n    model_path = \"/kaggle/input/llama-3/transformers/8b-chat-hf/1\"\n\n    # Check if the model directory exists\n    if not os.path.exists(model_path):\n        raise ValueError(f\"Model path does not exist: {model_path}\")\n\n    # Load tokenizer and model\n    tokenizer = AutoTokenizer.from_pretrained(model_path)\n    model = AutoModelForCausalLM.from_pretrained(model_path, torch_dtype=torch.float16, device_map='auto')\n\n    return model, tokenizer\n\n# Load the model and tokenizer\nllm, tokenizer = load_llama_model()\n","metadata":{"execution":{"iopub.status.busy":"2024-10-12T12:54:34.976593Z","iopub.execute_input":"2024-10-12T12:54:34.977388Z","iopub.status.idle":"2024-10-12T12:56:02.169379Z","shell.execute_reply.started":"2024-10-12T12:54:34.977347Z","shell.execute_reply":"2024-10-12T12:56:02.168137Z"},"trusted":true},"execution_count":15,"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c9cdef9c6b574565970519c8af48126e"}},"metadata":{}}]},{"cell_type":"code","source":"def extract_text_from_pdf(file_path):\n    text = \"\"\n    try:\n        with pdfplumber.open(file_path) as pdf:\n            for page in pdf.pages:\n                extracted = page.extract_text()\n                if extracted:\n                    text += extracted + \"\\n\"\n    except Exception as e:\n        print(f\"Error reading PDF: {e}\")\n        return \"\"\n    return text\n\ndef extract_text_via_ocr(file_path):\n    text = \"\"\n    with tempfile.TemporaryDirectory() as path:\n        try:\n            images = convert_from_path(file_path, output_folder=path)\n        except Exception as e:\n            print(f\"Error converting PDF to images: {e}\")\n            return \"\"\n        for img in images:\n            try:\n                text += pytesseract.image_to_string(img) + \"\\n\"\n            except Exception as e:\n                print(f\"Error with OCR on image: {e}\")\n                return \"\"\n    return text\n\ndef preprocess_text(text):\n    # Remove multiple spaces and newlines\n    text = re.sub(r'\\s+', ' ', text)\n    return text\n\ndef extract_invoice_data(text):\n    prompt = f\"\"\"\nYou are a model designed to extract invoice information. Please strictly extract and return the invoice information in the following JSON format, and nothing else:\n\nJSON Format:\n{{\n    \"Invoice Number\": \"\",\n    \"Invoice Date\": \"\",\n    \"Due Date\": \"\",\n    \"Total Amount\": \"\",\n    \"Vendor Name\": \"\",\n    \"Vendor Address\": \"\",\n    \"Buyer Name\": \"\",\n    \"Buyer Address\": \"\",\n    \"GSTIN Number\": \"\",\n    \"Bank Details\": {{\n        \"Name\": \"\",\n        \"Account Number\": \"\",\n        \"IFSC Code\": \"\"\n    }},\n    \"Payment Terms\": \"\"\n}}\n\nExtract the information strictly from the invoice text provided below:\n\n\\\"\\\"\\\" \n{text} \n\\\"\\\"\\\"\n\nEnsure that the JSON is valid and strictly adheres to the format. Return no additional explanations.\n\"\"\"\n    response = llm(\n        prompt,\n        max_tokens=1024,\n        #max_tokens=1024,\n        temperature=0.0,\n        stop=[\"\\\"\\\"\\\"\"]\n    )\n    return response\n\ndef parse_json(text):\n    try:\n        # Use regex to find the first JSON-like structure\n        json_text_match = re.search(r'\\{.*\\}', text, re.DOTALL)\n        if json_text_match:\n            json_text = json_text_match.group()\n            # Try loading the JSON\n            data = json.loads(json_text)\n            return data\n        else:\n            raise ValueError(\"No valid JSON found in the text.\")\n    except json.JSONDecodeError as e:\n        print(f\"JSON decode error: {e}\")\n        return None\n    except Exception as e:\n        print(f\"Failed to parse JSON: {e}\")\n        return None\n","metadata":{"execution":{"iopub.status.busy":"2024-10-12T13:25:47.138769Z","iopub.execute_input":"2024-10-12T13:25:47.139526Z","iopub.status.idle":"2024-10-12T13:25:47.151067Z","shell.execute_reply.started":"2024-10-12T13:25:47.139488Z","shell.execute_reply":"2024-10-12T13:25:47.150175Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"# Create a file uploader widget\nuploader = widgets.FileUpload(\n    accept='.pdf',  # Accept PDF files only\n    multiple=False  # Single file upload\n)\n\n# Display the uploader\ndisplay(uploader)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-12T13:25:47.661062Z","iopub.execute_input":"2024-10-12T13:25:47.661402Z","iopub.status.idle":"2024-10-12T13:25:47.670514Z","shell.execute_reply.started":"2024-10-12T13:25:47.661368Z","shell.execute_reply":"2024-10-12T13:25:47.669536Z"},"trusted":true},"execution_count":35,"outputs":[{"output_type":"display_data","data":{"text/plain":"FileUpload(value={}, accept='.pdf', description='Upload')","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4f856b85f1be4d10a5424de0883398f6"}},"metadata":{}}]},{"cell_type":"code","source":"def process_pdf(change):\n    # Check if a file is uploaded\n    if uploader.value:\n        # Clear previous outputs\n        clear_output(wait=True)\n        display(uploader)\n        \n        # Get the uploaded file\n        uploaded_file = next(iter(uploader.value.values()))\n        file_content = uploaded_file['content']\n        file_name = uploaded_file['metadata']['name']\n        \n        # Save the uploaded file to a temporary file\n        with tempfile.NamedTemporaryFile(delete=False, suffix=\".pdf\") as tmp_file:\n            tmp_file.write(file_content)\n            tmp_file_path = tmp_file.name\n        \n        print(\"üìÑ Processing the uploaded PDF...\")\n        \n        # Attempt to extract text directly\n        text = extract_text_from_pdf(tmp_file_path)\n        \n        # If no text found, perform OCR\n        if not text.strip():\n            print(\"üîç No text found using pdfplumber. Attempting OCR...\")\n            text = extract_text_via_ocr(tmp_file_path)\n        \n        text = preprocess_text(text)\n        \n        if not text.strip():\n            print(\"‚ùå Failed to extract text from the PDF.\")\n            return\n        else:\n            print(\"üìù Extracted Text:\")\n            print(\"-\" * 50)\n            print(text)\n            print(\"-\" * 50)\n        \n        # Extract structured data using LLaMA model\n        print(\"ü§ñ Extracting structured invoice data using LLaMA model...\")\n        model_response = extract_invoice_data(text)\n        \n        if model_response is None:\n            print(\"‚ùå Model inference failed.\")\n            return\n        else:\n            # Debugging: Display the raw model response\n            print(\"üì§ Raw Model Response:\")\n            print(\"-\" * 50)\n            print(model_response)\n            print(\"-\" * 50)\n        \n            # Check if response is a dictionary with choices\n            if isinstance(model_response, dict) and 'choices' in model_response:\n                if len(model_response['choices']) > 0:\n                    extracted_text = model_response['choices'][0]['text'].strip()\n                    extracted_data = parse_json(extracted_text)\n                else:\n                    print(\"‚ùå No choices available in the model response.\")\n                    extracted_data = None\n            else:\n                print(\"‚ùå Unexpected response format from the model.\")\n                extracted_data = None\n        \n            if extracted_data:\n                print(\"‚úÖ Extracted Invoice Data:\")\n                print(json.dumps(extracted_data, indent=4))\n            else:\n                print(\"‚ùå Failed to extract structured data from the model response.\")\n","metadata":{"execution":{"iopub.status.busy":"2024-10-12T13:25:48.613372Z","iopub.execute_input":"2024-10-12T13:25:48.614121Z","iopub.status.idle":"2024-10-12T13:25:48.625958Z","shell.execute_reply.started":"2024-10-12T13:25:48.614081Z","shell.execute_reply":"2024-10-12T13:25:48.624921Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"# Link the processing function to the uploader's 'value' attribute\nuploader.observe(process_pdf, names='value')\n","metadata":{"execution":{"iopub.status.busy":"2024-10-12T13:25:49.119746Z","iopub.execute_input":"2024-10-12T13:25:49.120099Z","iopub.status.idle":"2024-10-12T13:25:49.124232Z","shell.execute_reply.started":"2024-10-12T13:25:49.120063Z","shell.execute_reply":"2024-10-12T13:25:49.123309Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}